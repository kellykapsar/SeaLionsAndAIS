---
title: "SSLAvailAndCovarExtraction"
author: "Kelly Kapsar"
date: "10/1/2021"
output: html_document
---

```{r load libraries}

library(tidyr)
library(dplyr)
library(sf)
library(raster)
library(ggplot2)
library(scales)
library(ggmap)
library(amt) 

```


```{r read in data}

# Set seed
set.seed(1015)

# Projection information for WGS84/UTM Zone 5N (EPSG:32605)
prj <- 32605

# Create study area polygon
coords <- data.frame(lat=c(56, 62, 62, 56, 56), lon=c(-155, -155, -143, -143, -155), id="study")
study <- coords %>% 
         st_as_sf(coords = c("lon", "lat"), crs=4326) %>% 
         group_by(id) %>% 
         summarize(geometry = st_combine(geometry)) %>%  
         st_cast("POLYGON") %>% 
         st_transform(prj)

# Read in clean, non-land ssl used locations
ssl <- readRDS("../Data_Processed/Telemetry/watersealis.rds")
ssl$used <- factor(1)

# Read in covariates 
landmask <- raster("../Data_Processed/Landmask_GEBCO.tif")
dist_500m <- raster("../Data_Processed/Dist500m.tif") %>% raster::mask(landmask, maskvalue=1)
depth <- raster("../Data_Processed/Bathymetry.tif") %>% raster::mask(landmask, maskvalue=1)
dist_land <- raster("../Data_Processed/DistLand.tif") %>% raster::mask(landmask, maskvalue=1)
slope <- raster("../Data_Processed/slope.tif") %>% raster::mask(landmask, maskvalue=1)

ship <- readRDS("../Data_Processed/AIS_AllOther.rds") 
fish <- readRDS("../Data_Processed/AIS_Fishing.rds")
eke1 <- readRDS("../Data_Processed/eke_weekly_20181101-20200531.rds")
eke2 <- readRDS("../Data_Processed/eke_weekly_20200601-20200731.rds")
ssh1 <- readRDS("../Data_Processed/ssh_weekly_20181101-20200531.rds")
ssh2 <- readRDS("../Data_Processed/ssh_weekly_20200601-20200731.rds")
sst <- readRDS("../Data_Processed/sst_weekly.rds")
wind <- readRDS("../Data_Processed/wind_weekly.rds")

# Create a list of all covariate files  and check resolution 
raslist <- list(depth, dist_land, dist_500m, slope, ship, fish, sst, eke1, eke2, ssh1, ssh2, wind)
rasres <- lapply(raslist, function(x) res(x)/1000)

# Create a vector of covar names 
covar_names <- c("bathymetry", "dist_land", "dist_500m", "slope", "ship", "fish", "sst", "eke", "ssh", "wind")

# Function to identify random points within a set of polygons 
# This also extracts raster values for static variables in the covar stack 
# Accounts for points on land 

custom_extract_avail <- function(poly, covarstack, npts = 5){
  df <-  as.data.frame(sampleRandom(x=covarstack, size = npts, na.rm = TRUE, ext = as(poly, "Spatial"), xy = TRUE))
  df$used <- factor(0)
  df$date <- poly$date
  df$deploy_id <- poly$deploy_id
  df$choice_id <- poly$choice_id
  df$year <- poly$year
  df$month <- poly$month
  df$weekofyear <- poly$weekofyear
  return(df)
}


# Extract dynamic covariate data at used locations 
### Modified from FROM AMT PACKAGE
# https://github.com/jmsigner/amt/blob/master/R/extract_covariates.R
# Also helpful: https://cran.r-project.org/web/packages/amt/vignettes/p3_rsf.html
# I modified it so that it works with weekly timescale data 
# DOES NOT work with holes in the data set any more 

extract_covar_var_time_custom <- function(
  xy, t, covariates) {

  t_covar <- raster::getZ(covariates)
  t_obs <- format(as.POSIXct(t), "%G-W%V") # Convert timestamp to week
  # Same week of year as lubridate::isoweek(ssl_dates$date)
  wr <- sapply(t_obs, function(x) which(x == t_covar)) # Identify which slice to select
  ev <- raster::extract(covariates, xy) # Extract covariate values for all time slices at all used locations 
  cov_val <- ev[cbind(seq_along(wr), wr)] # select only the relevant time slice for each location
  return(cov_val)
}

```


```{r avail method 1: custom buffer size around used points, eval=FALSE}

# Create individually buffered points based on 
sealibuffs <- ssl %>% group_by(deploy_id) %>% st_buffer(dist=ssl$radius*1000) # Convert radius to m
# st_write(sealibuffs, "../Data_Processed/Telemetry/seali_SpeedBuffs.shp")

# Create a list of static covariates 
staticcovars <- raster::stack(dist_land, dist_500m, depth, slope)

# Create a list of all covariates and check resolution 
raslist <- list(depth, dist_land, dist_500m, slope, ship, fish, sst, eke1, eke2, ssh1, ssh2, wind)
rasres <- lapply(raslist, function(x) res(x)/1000)


# Extract available locations from buffered used locations 
# Takes ~ 1.3 hours 

# start <- proc.time()
# # q <- lapply(1:length(sealibuffs$deploy_id),
# #             function(x){custom_extract_avail(sealibuffs[x,], covarstack=staticcovars)})
# avail <- data.frame()
# for(i in 1:length(sealibuffs$deploy_id)){
#   if(i %% 100 == 0){print(i)}
#   q <- custom_extract_avail(sealibuffs[i,], covarstack=staticcovars)
#   avail <- rbind(avail, q)
# }
# 
# # avail <- do.call(rbind, q)
# proc.time()-start
# 
# saveRDS(avail, "../Data_Processed/Telemetry/Available_SpeedBuff_20211003.rds")

# browseURL("https://www.youtube.com/watch?v=K1b8AhIsSYQ")

# Read in previously extracted available locations (created from above code chunk)
avail <- readRDS("../Data_Processed/Telemetry/Available_SpeedBuff_20211003.rds")

# Rename x and y into northing and easting
avail <- avail %>% rename(northing = y, easting= x) %>% 
                   st_as_sf(coords=c("easting", "northing"), remove=F) %>%
                   mutate(used=factor(0))
st_crs(avail) <- st_crs(ssl)

# Extract static covariates at used locations
ssl <- cbind(ssl, raster::extract(staticcovars, ssl))

# Combine available data with used data 
ssl1 <- bind_rows(ssl, avail)

# Extract dynamic weekly covariate values at used and available locations 
# Extract covariate data at used locations 
ssl1$sst <- extract_covar_var_time_custom(xy= st_coordinates(ssl1), t = ssl1$date, covariates=sst)
ssl1$wind <- extract_covar_var_time_custom(xy= st_coordinates(ssl1), t = ssl1$date, covariates=wind)
ssl1$ship <- extract_covar_var_time_custom(xy= st_coordinates(ssl1), t = ssl1$date, covariates=ship)
ssl1$fish <- extract_covar_var_time_custom(xy= st_coordinates(ssl1), t = ssl1$date, covariates=fish)
ssl11 <- ssl1 %>% filter(!date > as.POSIXct("2020-06-01", format="%Y-%m-%d")) %>% mutate(
  ssh = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=ssh1),
  eke = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=eke1)
)
ssl12 <- ssl1 %>% filter(date > as.POSIXct("2020-06-01", format="%Y-%m-%d")) %>% mutate(
  ssh = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=ssh2),
  eke = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=eke2)
)
ssl1 <- rbind(ssl11, ssl12)

# Drop geometry and standardize column names to lowercase with underscores between words
colnames(ssl1) <- tolower(colnames(ssl1)) 
ssl1 <- ssl1 %>% st_drop_geometry %>% rename(dist_land = distland, dist_500m = dist500m) %>% 
                  dplyr::select(deploy_id, choice_id, used, year, month, weekofyear, lon, lat, 
                                northing, easting, all_of(covar_names)) 

# Convert extracted values to numeric
ssl1[,names(ssl1) != "deploy_id"] <- apply(ssl1[,names(ssl1) != "deploy_id"], 2, function(x){as.numeric(as.character(x))})

# Save output
saveRDS(ssl1, "../Data_Processed/Telemetry/UsedAndAvail_SpeedBuff_20211003.rds")

```

```{r avail method 2: enlarged buffer size around used points, eval=FALSE}

# Create individually buffered points based on 
sealibuffs <- ssl %>% group_by(deploy_id) %>% st_buffer(dist=20000) # Convert radius to m
# st_write(sealibuffs, "../Data_Processed/Telemetry/seali_20kmBuffs.shp")

# Create a list of static covariates 
staticcovars <- raster::stack(dist_land, dist_500m, depth, slope)

# Create a list of all covariates and check resolution 
raslist <- list(depth, dist_land, dist_500m, slope, ship, fish, sst, eke1, eke2, ssh1, ssh2, wind)
rasres <- lapply(raslist, function(x) res(x)/1000)


# Extract available locations from buffered used locations 
# Takes ~ 1.3 hours 

# start <- proc.time()
# # q <- lapply(1:length(sealibuffs$deploy_id),
# #             function(x){custom_extract_avail(sealibuffs[x,], covarstack=staticcovars)})
# avail <- data.frame()
# for(i in 1:length(sealibuffs$deploy_id)){
#   if(i %% 100 == 0){print(i)}
#   q <- custom_extract_avail(sealibuffs[i,], covarstack=staticcovars)
#   avail <- rbind(avail, q)
# }
# 
# # avail <- do.call(rbind, q)
# proc.time()-start
# 
# saveRDS(avail, "../Data_Processed/Telemetry/Available_20kmBuff_20211003.rds")

# browseURL("https://www.youtube.com/watch?v=K1b8AhIsSYQ")

# Read in previously extracted available locations (created from above code chunk)
avail <- readRDS("../Data_Processed/Telemetry/Available_20kmBuff_20211003.rds") %>% mutate(used=factor(used)) # Fixed in code above can remove once rerun

# Rename x and y into northing and easting
avail <- avail %>% rename(northing = y, easting= x) %>% st_as_sf(coords=c("easting", "northing"), remove=F) 
st_crs(avail) <- st_crs(ssl)

# Extract static covariates at used locations
ssl <- cbind(ssl, raster::extract(staticcovars, ssl))

# Combine available data with used data 
ssl2 <- bind_rows(ssl, avail)

# Extract dynamic weekly covariate values at used and available locations 
# Extract covariate data at used locations 
ssl2$sst <- extract_covar_var_time_custom(xy= st_coordinates(ssl2), t = ssl2$date, covariates=sst)
ssl2$wind <- extract_covar_var_time_custom(xy= st_coordinates(ssl2), t = ssl2$date, covariates=wind)
ssl2$ship <- extract_covar_var_time_custom(xy= st_coordinates(ssl2), t = ssl2$date, covariates=ship)
ssl2$fish <- extract_covar_var_time_custom(xy= st_coordinates(ssl2), t = ssl2$date, covariates=fish)
ssl21 <- ssl2 %>% filter(!date > as.POSIXct("2020-06-01", format="%Y-%m-%d")) %>% mutate(
  ssh = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=ssh1),
  eke = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=eke1)
)
ssl22 <- ssl2 %>% filter(date > as.POSIXct("2020-06-01", format="%Y-%m-%d")) %>% mutate(
  ssh = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=ssh2),
  eke = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=eke2)
)
ssl2 <- rbind(ssl21, ssl22)

# Drop geometry and standardize column names to lowercase with underscores between words
colnames(ssl2) <- tolower(colnames(ssl2)) 
ssl2 <- ssl2 %>% st_drop_geometry %>% rename(dist_land = distland, dist_500m = dist500m) %>% 
                  dplyr::select(deploy_id, choice_id, used, year, month, weekofyear, lon, lat, 
                                northing, easting, all_of(covar_names)) 


# Convert extracted values to numeric
ssl2[,names(ssl2) != "deploy_id"] <- apply(ssl2[,names(ssl2) != "deploy_id"], 2, function(x){as.numeric(as.character(x))})

# Save output
saveRDS(ssl2, "../Data_Processed/Telemetry/UsedAndAvail_20kmBuff_20211003.rds")

```

```{r avail method 3: resample covars to 5 km, eval=FALSE}


# Create individually buffered points based on 
sealibuffs <- ssl %>% group_by(deploy_id) %>% st_buffer(dist=ssl$radius*1000) # Convert radius to m
# st_write(sealibuffs, "../Data_Processed/sealibuffs.shp")

# Create 5km raster template
ras_5km <- crop(fish, study)
res(ras_5km) <- 5000

# NOT SURE WHY THIS ISN'T WORKING.... WHAT'S UP WITH THE FILE CONNECTION? WILL TRY OVER AGAIN FROM BEGINNING
depth_5km <- resample(depth, ras_5km)
dist_land_5km <- resample(dist_land, ras_5km)
dist_500m_5km <- resample(dist_500m, ras_5km)
slope_5km <- resample(slope, ras_5km)
ship_5km <- resample(ship, ras_5km) %>% setZ(getZ(ship))
fish_5km <- resample(fish, ras_5km) %>% setZ(getZ(fish))
sst_5km <- resample(sst, ras_5km) %>% setZ(getZ(sst))
eke1_5km <- resample(eke1, ras_5km) %>% setZ(getZ(eke1))
eke2_5km <- resample(eke2, ras_5km) %>% setZ(getZ(eke2))
ssh1_5km <- resample(ssh1, ras_5km) %>% setZ(getZ(ssh1))
ssh2_5km <- resample(ssh2, ras_5km) %>% setZ(getZ(ssh2))
wind_5km <- resample(wind, ras_5km)  %>% setZ(getZ(wind))


# Create a list of static covariates
staticcovars <- raster::stack(dist_land_5km, dist_500m_5km, depth_5km, slope_5km)

# Create a list of all covariates and check resolution
raslist <- list(depth_5km, dist_land_5km, dist_500m_5km, slope_5km,
                ship_5km, fish_5km, sst_5km, eke1_5km, eke2_5km, ssh1_5km, ssh2_5km, wind_5km)
rasres <- lapply(raslist, function(x) res(x)/1000)

# Extract available locations from buffered used locations
# Takes ~ 1.3 hours
# 
# start <- proc.time()
# # q <- lapply(1:length(sealibuffs$deploy_id),
# #             function(x){custom_extract_avail(sealibuffs[x,], covarstack=staticcovars)})
# avail <- data.frame()
# for(i in 1:length(sealibuffs$deploy_id)){
#   if(i %% 100 == 0){print(i)}
#   q <- custom_extract_avail(sealibuffs[i,], covarstack=staticcovars)
#   avail <- rbind(avail, q)
# }
# 
# # avail <- do.call(rbind, q)
# proc.time()-start
# 
# saveRDS(avail, "../Data_Processed/Telemetry/Available_5kmCell_20211003.rds")

# browseURL("https://www.youtube.com/watch?v=K1b8AhIsSYQ")

# Read in previously extracted available locations (created from above code chunk)
avail <- readRDS("../Data_Processed/Telemetry/Available_5kmCell_20211003.rds")

# Rename x and y into northing and easting
avail <- avail %>% rename(northing = y, easting= x) %>% 
                   st_as_sf(coords=c("easting", "northing"), remove=F) %>%
                   mutate(used=factor(0))
st_crs(avail) <- st_crs(ssl)

# Extract static covariates at used locations
ssl <- cbind(ssl, raster::extract(staticcovars, ssl))

# Combine available data with used data 
ssl3 <- bind_rows(ssl, avail)

# Extract dynamic weekly covariate values at used and available locations 
# Extract covariate data at used locations 
ssl3$sst <- extract_covar_var_time_custom(xy= st_coordinates(ssl3), t = ssl3$date, covariates=sst_5km)
ssl3$wind <- extract_covar_var_time_custom(xy= st_coordinates(ssl3), t = ssl3$date, covariates=wind_5km)
ssl3$ship <- extract_covar_var_time_custom(xy= st_coordinates(ssl3), t = ssl3$date, covariates=ship_5km)
ssl3$fish <- extract_covar_var_time_custom(xy= st_coordinates(ssl3), t = ssl3$date, covariates=fish_5km)
ssl3a <- ssl3 %>% filter(!date > as.POSIXct("2020-06-01", format="%Y-%m-%d")) %>% mutate(
  ssh = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=ssh1_5km),
  eke = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=eke1_5km)
)
ssl3b <- ssl3 %>% filter(date > as.POSIXct("2020-06-01", format="%Y-%m-%d")) %>% mutate(
  ssh = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=ssh2_5km),
  eke = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=eke2_5km)
)
ssl3 <- rbind(ssl3a, ssl3b)

# Drop geometry and standardize column names to lowercase with underscores between words
colnames(ssl3) <- tolower(colnames(ssl3)) 
ssl3 <- ssl3 %>% st_drop_geometry() %>% rename(dist_land = distland, dist_500m = dist500m) %>% 
                  dplyr::select(deploy_id, choice_id, used, year, month, weekofyear, lon, lat, northing, 
                                easting, all_of(covar_names)) 

# Convert extracted values to numeric
ssl3[,names(ssl3) != "deploy_id"] <- apply(ssl3[,names(ssl3) != "deploy_id"], 2, function(x){as.numeric(as.character(x))})

# Save output
saveRDS(ssl3, "../Data_Processed/Telemetry/UsedAndAvail_5kmCell_20211003.rds")

```

```{r avail method 4: weekly minimum convex polygon home ranges}

# Create an ID column that identifies each unique individual/year/week combination
ssl$weeklyhr_id <- factor(paste0(ssl$deploy_id, ssl$year, ssl$weekofyear))

# # Isolate out variables of interest 
ssl_simple <- ssl %>% select(weeklyhr_id, date, lon, lat)

# Turn into an amt track
trk <- mk_track(st_drop_geometry(ssl_simple), .x=lon, .y=lat, .t=date, id = weeklyhr_id, date=date,
                crs = CRS("+init=epsg:4326"))
trk.class<-class(trk)

# Calculate time of day based on lat/lon and timestamp
trk <- trk %>% time_of_day()
class(trk) <- trk.class

#' Now, we can transform back to geographic coordinates
trk <- amt::transform_coords(trk, CRS("+init=epsg:32605"))

# Summarize sampling rate
summarize_sampling_rate(trk)
summarize_sampling_rate_many(trk, c("id"))

# Create random points around each weekly homerange
# From https://movebankworkshopraleighnc.netlify.app/2019outputfiles/fisherrsf
avail_pts_nstd <- trk %>%
             nest(data=-"id") %>% 
             # Note sure what factor = 5 does, but I think maybe its the available to used ratio? 
             # For some reason it's giving me 10 available points per used point
             mutate(rnd_pts = map(data, function(d) random_points(d, factor=5, hr="mcp")),
                    hr_mcp = map(data, function(d) hr_mcp(d, levels=c(0.95)) %>% hr_isopleths()))
avail_pts_nstd$deploy_id <- substr(avail_pts_nstd$id, 1, 13)
avail_pts_nstd$year <- substr(avail_pts_nstd$id, 14, 17)
avail_pts_nstd$weekofyear <- substr(avail_pts_nstd$id, 18, 19)


# Create polygon features from MCPs
ssl_hr <- avail_pts_nstd %>% select(id, deploy_id, year, weekofyear, hr_mcp) %>% unnest(cols=c(id)) 
class(ssl_hr) <- "data.frame"

# Extract the homerange information for each sealiweek
ssl_hr <- ssl_hr %>%
           dplyr::mutate(hr_mcp = matrix(hr_mcp),
           level = sapply(hr_mcp, function(x) magrittr::extract2(x, 1)),
           what = sapply(hr_mcp, function(x) magrittr::extract2(x, 2)),
           area = sapply(hr_mcp, function(x) magrittr::extract2(x, 3)),
           geometry = sapply(hr_mcp, function(x) magrittr::extract2(x, 4)),
           hr_mcp = NULL) %>% 
          st_as_sf(crs=prj)
ssl_hr$area <- round(ssl_hr$area, 3)

# Save output polygons 
# st_write(ssl_hr, "../Data_Processed/Telemetry/Homerange_MCP_weekly_20211007.shp")

# Isolate out newly derived available coordinates
avail_pts <- avail_pts_nstd %>% select(id, deploy_id, year, weekofyear, rnd_pts) %>% unnest(cols=c(id, rnd_pts))
class(avail_pts) <- "data.frame"

# Convert columns to numeric
avail_pts$year <- as.numeric(avail_pts$year)
avail_pts$weekofyear <- as.numeric(avail_pts$weekofyear)
avail_pts$x_ <- as.numeric(avail_pts$x_)
avail_pts$y_ <- as.numeric(avail_pts$y_)

# Turn into spatial object
avail_pts_sf <- st_as_sf(avail_pts, coords=c("x_", "y_"), crs=prj, remove=FALSE)

# Extract week of year as data from original data 
ssl_dates <- ssl %>% st_drop_geometry() %>% group_by(weeklyhr_id) %>% summarize(date=min(date))
avail_pts_sf <- left_join(avail_pts_sf, ssl_dates, by=c("id" = "weeklyhr_id"))

# Check that week of year re-calculation worked okay 
# It works!
# ssl_dates$weekofyear <- lubridate::isoweek(ssl_dates$date)
# ssl_dates$weekofyear2 <- format(ssl_dates$date, "%G-W%V")
# ssl_datetest <- left_join(ssl, ssl_dates, by= "weeklyhr_id")
# length(which(ssl_datetest$weekofyear.x != ssl_datetest$weekofyear.y))

# Create a list of static covariates 
staticcovars <- raster::stack(dist_land, dist_500m, depth, slope)

# Extract values at used and available locations
avail_pts_sf <- cbind(avail_pts_sf, raster::extract(staticcovars, avail_pts_sf))

# Rename to match other naming schemes
ssl4 <- avail_pts_sf


# Extract dynamic weekly covariate values at used and available locations 
# Extract covariate data at used locations 
ssl4$sst <- extract_covar_var_time_custom(xy= st_coordinates(ssl4), t = ssl4$date, covariates=sst)
ssl4$wind <- extract_covar_var_time_custom(xy= st_coordinates(ssl4), t = ssl4$date, covariates=wind)
ssl4$ship <- extract_covar_var_time_custom(xy= st_coordinates(ssl4), t = ssl4$date, covariates=ship)
ssl4$fish <- extract_covar_var_time_custom(xy= st_coordinates(ssl4), t = ssl4$date, covariates=fish)
ssl4a <- ssl4 %>% filter(!date > as.POSIXct("2020-06-01", format="%Y-%m-%d")) %>% mutate(
  ssh = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=ssh1),
  eke = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=eke1)
)
ssl4b <- ssl4 %>% filter(date > as.POSIXct("2020-06-01", format="%Y-%m-%d")) %>% mutate(
  ssh = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=ssh2),
  eke = extract_covar_var_time_custom(xy= st_coordinates(.), t = .data$date, covariates=eke2)
)
ssl4 <- rbind(ssl4a, ssl4b)

# convert column names to lowercase 
colnames(ssl4) <- tolower(colnames(ssl4)) 


##################################################################
############# CALCULATE PROXIMITY TO FISHING VESSELS ############# 
##################################################################

# Boundary for AIS data acquisition
aisbound_sf <- st_read("../Data_Raw/AIS_Bounds_FromAP/ais_reshape.shp") %>% st_transform(prj)

# Identify SSL locations outside the AIS boundaries
ssl4$ais_bounds <- st_intersects(ssl4, aisbound_sf, sparse=FALSE)

# Import ship data, create sf objects, combine into one sf object, and generate year value 
ships<- list.files("../Data_Raw/AIS_SSLWeeklySubset/Vector", pattern = ".shp")
ships <- lapply(ships, function(x){st_read(paste0("../Data_Raw/AIS_SSLWeeklySubset/Vector/", x)) %>% st_transform(prj)})
ships <- do.call(rbind, ships) # Combine all ships into one sf object
ships <- ships %>% mutate(year = substr(AIS_ID, 11, 14)) # Extract year from AIS_ID

# Standardize dates 
ships$date <- as.Date(substr(ships$AIS_ID, 11, 18),format = "%Y%m%d") %>% format(., "%G-W%V")
ssl4$date <- format(ssl4$date, "%G-W%V")

# Create nested shipping data frame 
ships_nest <- ships[which(ships$AIS_Typ != "Fishing"),] %>% group_nest(date)
fish_nest <- ships[which(ships$AIS_Typ == "Fishing"),] %>% group_nest(date)

# Find nearest line to each point 
prox <- function(points, lines){
  # Isolate out only lines from the week of interest and extract from nested data
  l <- lines[which(lines$date == points$date[1]),] %>% 
        unnest(., cols=c(data)) %>%
        mutate(geometry = st_sfc(geometry)) %>%
        st_as_sf()
  # Calculate nearest line to each point
  nearest <- st_nearest_feature(points, l)
  # Calculate distance to that line, convert to kilometers, and round 
  dist <- round(as.numeric(st_distance(points, l[nearest,], by_element=T))/1000, 4) 
  return(dist)
}

# TAKES ~1.5 HRS
start <- proc.time()
newdata <- ssl4 %>% # to sample random points: sample(1:length(ssl4$weeklyhr_id), 1000, replace=F)
             group_nest(date, keep=TRUE) %>% # Create set of nested data frames by week
             rename(date_outer = date) %>% 
             mutate(data = purrr::map(data, # Go within the data frame 
                ~mutate(.x, prox_ships_km = prox(.x, ships_nest), 
                            prox_fish_km = prox(.x, fish_nest)))) %>% # Add new columns within each df to calculate proximity
             unnest(cols=c(data)) %>%         
             mutate(geometry = st_sfc(geometry)) %>%
             st_as_sf()
saveRDS(newdata, "../Data_Processed/Telemetry/TEMP_ALLCOVARS.rds")
proc.time()-start

#################################################
############# cLEAN UP DATA AND SAVE ############ 
#################################################

# Standardize column names
ssl4 <- ssl4 %>% st_drop_geometry() %>% rename(dist_land = distland, dist_500m = dist500m,
                                               weeklyhr_id = id, used=case_, northing = y_, easting = x_) %>% 
                  dplyr::select(weeklyhr_id, deploy_id, used, date, year, weekofyear, northing, easting, 
                                ais_bounds, all_of(covar_names)) 


ssl4 <- st_as_sf(ssl4, coords = c("easting", "northing"), crs=prj, remove=FALSE)

# Save output
saveRDS(ssl4, "../Data_Processed/Telemetry/UsedAndAvail_WeeklyMCP_20211014.rds")
st_write(ssl4, "../Data_Processed/Telemetry/UsedAndAvail_WeeklyMCP_20211014.shp")

# See how many complete cases are left in available 
test <- ssl4 %>% st_drop_geometry() %>% filter(complete.cases(.), ais_bounds=TRUE)
temp <- test %>% group_by(weeklyhr_id, used) %>% summarize(n=n())



```

```{r testing contamination, eval=FALSE} 

avail1 <- readRDS("../Data_Processed/Telemetry/UsedAndAvail_SpeedBuff_20211003.rds") 
avail2 <- readRDS("../Data_Processed/Telemetry/UsedAndAvail_20kmBuff_20211003.rds") 
avail3 <- readRDS("../Data_Processed/Telemetry/UsedAndAvail_5kmCell_20211003.rds") 

contamination_calc <- function(usedandavail){
    used1 <- usedandavail %>% 
             filter(used==1) %>% 
             dplyr::select(-used)
    temp <- left_join(usedandavail, used1, by="choice_id") %>% filter(used==0) 
    
    sames <- temp %>% mutate(bathymetry = ifelse(bathymetry.x == bathymetry.y, 1, 0),
                         dist_land = ifelse(dist_land.x == dist_land.y, 1, 0),
                         dist_500m = ifelse(dist_500m.x == dist_500m.y, 1, 0),
                         slope = ifelse(slope.x == slope.y, 1, 0),
                         ship = ifelse(ship.x == ship.y, 1, 0),
                         fish = ifelse(fish.x == fish.y, 1, 0),
                         sst = ifelse(sst.x == sst.y, 1, 0),
                         eke = ifelse(eke.x == eke.y, 1, 0),
                         ssh = ifelse(ssh.x == ssh.y, 1, 0),
                         wind = ifelse(wind.x == wind.y, 1, 0),
                          ) %>% 
                      dplyr::select(choice_id, bathymetry, dist_land, dist_500m, slope, ship, fish, sst, eke, ssh, wind)

     sames <- as.data.frame(apply(sames, 2, as.numeric))
     grand_contamination <- round(apply(sames, 2, function(x){sum(x, na.rm=T)})/length(sames$choice_id), 2)
     return(as.data.frame(grand_contamination))
     #    
     # contam <- sames %>% 
     #            group_by(choice_id) %>%
     #            summarize(Bathymetry_con=sum(Bathymetry)/5,
     #                      dist_land_con=sum(dist_land)/5,
     #                      dist_500m_con=sum(dist_500m)/5,
     #                      slope_con=sum(slope)/5,
     #                      ship_con=sum(ship)/5,
     #                      fish_con=sum(fish)/5,
     #                      sst_con=sum(sst)/5,
     #                      eke_con=sum(eke)/5,
     #                      ssh_con=sum(ssh)/5,
     #                      wind_con=sum(wind)/5
     #                      )

}

contamination <- cbind(contamination_calc(avail1), contamination_calc(avail2), contamination_calc(avail3)) 
colnames(contamination) <- c("rad_spd", "rad_20km", "resamp_5km")


```








