---
title: "Covariate Data Processing"
author: "Kelly Kapsar"
date: "11/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Import libraries. 
```{r message=FALSE, warning=FALSE}
library(tidyr)
library(dplyr)
library(sf)
library(raster)
library(ggplot2)
library(marmap)
library(ncdf4)
library(anytime)
library(rgdal)
library(scales)

```

Study area boundaries. 

```{r study area warning=FALSE}
# Projection information for WGS84/UTM Zone 5N (EPSG:32605)
prj <- 32605

# Create study area polygon
coords <- data.frame(lat=c(56, 62, 62, 56, 56), lon=c(-155, -155, -143, -143, -155), id="study")
study <- coords %>% 
         st_as_sf(coords = c("lon", "lat"), crs=4326) %>% 
         group_by(id) %>% 
         summarize(geometry = st_combine(geometry)) %>%  
         st_cast("POLYGON") %>% 
         st_transform(prj)
# st_write(study, "../Data_Raw/studyarea.shp")

basemap <- read_sf("../Data_Raw/BBmap.shp") %>% st_transform(prj) %>%  st_buffer(0)

# Crop basemap to buffered extent of study area 
study.buff <- st_buffer(study, 100000) # Buffer study area by 100 km
basemap.crop <- st_crop(basemap, study.buff)

# Map of study area 
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_sf(data=study, fill=NA, color="red")

# Get latlong coordinates for study area for use in downloading other data sets
studylatlon <- study %>% st_transform(4269) %>% st_bbox()
```

1 km land mask layer. 

```{r land mask kodiak, eval=F}
# Open netcdf file 
landmask <- nc_open("../Data_Raw/arc/base/analysis_masks/kod_mask_1k_u5w84.nc")
# Save metadata to a text file
{
  sink('../Data_Raw/arc/base/analysis_masks/kod_mask_1k_u5w84.txt')
  print(landmask)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(landmask, "x")
lat <- ncvar_get(landmask, "y", verbose = F)

head(lon)

# Read in data from the variable and verify the dimensions of the array
landmask.array <- ncvar_get(landmask, "kod_mask_1k_u5w84") # 3dim array
dim(landmask.array)

# Identify fill value and replace with NA
fillvalue <- ncatt_get(landmask, "kod_mask_1k_u5w84","missing_value")
fillvalue

landmask.array[landmask.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(landmask)

# Create raster of landmask
landmask.r <- raster(t(landmask.array), 
                xmn=min(lon), xmx=max(lon), ymn=min(lat),ymx=max(lat),
                # CRS from metadata
                crs=CRS("+proj=utm +zone=5 +datum=WGS84 +units=m +no_defs")) 

landmask.df <- as.data.frame(landmask.r, xy=TRUE)
colnames(landmask.df) <- c("x","y","water")

plot(landmask.r)

# Map of study area with landmask data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=landmask.df, aes(x=x, y=y, fill=water), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")
```

```{r land mask pws, eval=F}

############################################################
# SOMETHING'S WRONG WITH THE PROJECTION...IT'S APPEARING IN ZONE 5 INSTEAD OF ZONE 6

# Open netcdf file 
landmask2 <- nc_open("../Data_Raw/arc/base/analysis_masks/pws_mask_1k_u6w84.nc")
# Save metadata to a text file
{
  sink('../Data_Raw/arc/base/analysis_masks/pws_mask_1k_u6w84.txt')
  print(landmask2)
  sink()
}

# Read lat lon and time for each observation
lon2 <- ncvar_get(landmask2, "x")
lat2 <- ncvar_get(landmask2, "y", verbose = F)

head(lon2)

# Read in data from the variable and verify the dimensions of the array
landmask2.array <- ncvar_get(landmask2, "pws_mask_1k_u6w84") # 3dim array
dim(landmask2.array)

# Identify fill value and replace with NA
fillvalue2 <- ncatt_get(landmask2, "pws_mask_1k_u6w84","missing_value")
fillvalue2

landmask2.array[landmask2.array == fillvalue2$value] <- NA

# Close netcdf file
nc_close(landmask2)

# Create raster of landmask
landmask2.r <- raster(t(landmask2.array), 
                xmn=min(lon2), xmx=max(lon2), ymn=min(lat2),ymx=max(lat2),
                # CRS from metadata
                crs=CRS("+proj=utm +zone=6 +datum=WGS84 +units=m +no_defs")) #%>% 
                # flip(direction="x") %>%
                # flip(direction="y") 

landmask2.df <- as.data.frame(landmask2.r, xy=TRUE)
colnames(landmask2.df) <- c("x","y","water")

plot(landmask2.r)


# Map of study area with landmask data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=landmask2.df, aes(x=x, y=y, fill=water), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")
```


## AIS Data
```{r ais, warning=FALSE}

# Boundary for AIS data acquisition
aisbound_sf <- st_read("../Data_Raw/AIS_Bounds_FromAP/ais_reshape.shp") %>% st_transform(prj) %>% st_crop(study)
aisbound_sp <- aisbound_sf %>% as("Spatial")

# Import raster, reproject to 4336, and crop to study area
fishinglist <- list.files("../Data_Processed/AIS/", pattern="Fishing")
otherlist <- list.files("../Data_Processed/AIS/", pattern="Other")
cargolist <- list.files("../Data_Processed/AIS/", pattern="Cargo")
tankerlist <- list.files("../Data_Processed/AIS/", pattern="Tanker")

# Create raster bricks for each ship type 
fishingras <- lapply(fishinglist, 
                     function(x){projectRaster(raster::raster(paste0("../Data_Processed/AIS/", x)), crs=prj)})
fishingbrick <- raster::brick(fishingras) %>% raster::mask(aisbound_sp)

otherras <- lapply(otherlist, 
                     function(x){projectRaster(raster::raster(paste0("../Data_Processed/AIS/", x)), crs=prj)})
otherbrick <- raster::brick(otherras) %>% raster::mask(aisbound_sp)

cargoras <- lapply(cargolist, 
                     function(x){projectRaster(raster::raster(paste0("../Data_Processed/AIS/", x)), crs=prj)})
cargobrick <- raster::brick(cargoras) %>% raster::mask(aisbound_sp)

tankerras <- lapply(tankerlist, 
                     function(x){projectRaster(raster::raster(paste0("../Data_Processed/AIS/", x)), crs=prj)})
tankerbrick <- raster::brick(tankerras) %>% raster::mask(aisbound_sp)

shippingbrick <- otherbrick + cargobrick + tankerbrick

# Convert units to km 
shippingbrick <- shippingbrick/1000
fishingbrick <- fishingbrick/1000

# There's a faster way to do this, but I'm too tired right now
yearmon <- seq(as.Date("2018/11/15"), as.Date("2020/7/15"), "month")
names(shippingbrick) <- yearmon
names(fishingbrick) <- yearmon

shippingbrick <- raster::setZ(shippingbrick, yearmon)
fishingbrick <- raster::setZ(fishingbrick, yearmon)

# Save raster bricks as netcdf files 
# Save output file
writeRaster(shippingbrick, "../Data_Processed/AIS_AllOther.nc",
              overwrite=TRUE, format="CDF",
              varname="intensity", varunit="km",
              longname="Shipping intensity (km travelled per cell) -- raster brick to netCDF",
              xname="lon",   yname="lat",zname="time",
              zunit="numeric")

saveRDS(shippingbrick, "../Data_Processed/AIS_AllOther.rds")

writeRaster(fishingbrick, "../Data_Processed/AIS_Fishing.nc",
              overwrite=TRUE, format="CDF",
              varname="intensity", varunit="km",
              longname="Shipping intensity (km travelled per cell) -- raster brick to netCDF",
              zname="time", xname="lon",   yname="lat")

saveRDS(fishingbrick, "../Data_Processed/AIS_Fishing.rds")
# writeRaster(fishingbrick, "../Data_Processed/AIS_Fishing.nc",
#               overwrite=TRUE, format="CDF")
# Plot results
fish.df <- as.data.frame(fishingbrick[[1]], xy=TRUE)  %>% drop_na()
colnames(fish.df) <- c("x","y","intensity")

# Save raster object 
# raster::writeRaster(bathy, "../Data_Processed/bathemtry_GEBCO_cropped_4336.tif")

# Map of study area with bathymetric data 
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=fish.df, aes(x=x, y=y, fill=intensity), alpha=0.9) +
  # geom_sf(data=aisbound_sf, fill=NA, color="blue" )+
  geom_sf(data=study, fill=NA, color="red") +
  scale_fill_gradient2(trans="log10", low = "black", mid="gray", high="red")

```

## Bathymetry 

Bathymetry data were collected from the [General Bathymetric Chart of the Oceans](gebco.net). You can use the marmap package to load the data and create a "bathy" object type, but I'm not sure exactly how to work with that kind of object, so I just imported the tif data and converted into a raster.    

```{r bathymetry, warning=FALSE}

# bathymarmap <- marmap::getNOAA.bathy(lon1=-155, lon2=-143, lat1=56, lat2=62, resolution=3) 
# # resolution units are in minutes (3 minutes = 0.05 degrees)

# Import raster, reproject to 4336, and crop to study area
bathy <- raster::raster("../Data_Raw/GEBCO_16_Aug_2021/gebco_2021_n64.0_s54.0_w-157.0_e-141.0.tif") %>%
  projectRaster(crs=prj) %>%
  raster::crop(study)

bathyDf <- as.data.frame(bathy, xy=TRUE) %>% drop_na()
colnames(bathyDf) <- c("x","y","depth")

# Save raster object 
# raster::writeRaster(bathy, "../Data_Processed/bathemtry_GEBCO_cropped_4336.tif")

# Map of study area with bathymetric data 
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=bathyDf, aes(x=x, y=y, fill=depth), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# writeRaster(bathy, "../Data_Processed/Bathymetry.tif")

```

## Landmask 

This landmask is at the same scale as the bathymetry data. Note: Zero values were included as water and not land.

```{r GEBCO landmask}
landmask <- bathy
landmask[landmask > 0] <- 1
landmask[landmask < 0 | landmask == 0] <- NA

landmaskDf <- as.data.frame(landmask, xy=TRUE) %>% drop_na()
colnames(landmaskDf) <- c("x","y","land")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_tile(data=landmaskDf, aes(x=x, y=y, fill=land), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# writeRaster(landmask,"../Data_Processed/Landmask_GEBCO.tif")
```

## Slope

```{r slope}

slope <- terrain(bathy, opt="slope", unit="radians", neighbors=8)


slopeDf <- as.data.frame(slope, xy=TRUE)  %>% drop_na()
colnames(slopeDf) <- c("x","y","slope")

# Map of study area with bathymetric data 
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=slopeDf, aes(x=x, y=y, fill=slope), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


# writeRaster(slope, "../Data_Processed/Slope.tif")
```

## Distance to land 

```{r dist2land}
# # Alternate method: Get depth data from NOAA 
# depth <- getNOAA.bathy(lat1=55, lat2=62, lon1=-143, lon2=-156, resolution = 1)
# 
# # Creating color palettes
# blues <- c("lightsteelblue4", "lightsteelblue3",
# "lightsteelblue2", "lightsteelblue1")
# greys <- c(grey(0.6), grey(0.93), grey(0.99))
# 
# # Plot depth data 
# plot(depth, image = TRUE, land = TRUE, lwd = 0.03, 
#      bpal = list(c(0, max(depth), greys),c(min(depth), 0, blues)))
# # Add coastline
# plot(depth, n = 1, lwd = 0.4, add = TRUE)
# 
# # summary(depth)
# 
# # Transect of depth profile at 58N across study area 
# trsect <- get.transect(depth, -155, 58, -148, 58, distance = TRUE)
# plotProfile(trsect)


# Calculate distance to nearest NA cell for all cells in landmask raster 
distland2 <- bathy
values(distland2)[values(distland2) <= 0] = NA

# ID cells on land and water
land <- distland2 > 0
water <- distland2 <= 0

# Land = 1, isobath = 2
distland2[water] <- NA
distland2[land] <- 2

# Calculate distance to land 
distland2 <- gridDistance(distland2, origin = 2)/1000

# Plot results
distland2.df <- as.data.frame(distland2, xy=TRUE) %>% drop_na()
colnames(distland2.df) <- c("x","y","distland")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=distland2.df, aes(x=x, y=y, fill=distland), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# Save output
# writeRaster(distland2, "../Data_Processed/DistLand.tif")
```

## Distance to shelf break

Calculate distance to nearest cell between 400 and 500 m depth. 

```{r 500m shelf break}

# Based on this tutorial: 
# https://www.r-bloggers.com/2020/02/three-ways-to-calculate-distances-in-r/

bathy2 <- bathy

# ID cells on land, shallower than isobath, and deeper than isobath
land <- bathy2 > 0
shallow <- bathy2 > -400
deep <- bathy2 < -500 

# Land = 1, isobath = 2
bathy2[!shallow & !deep] <- 2
bathy2[land] <- 1

# Calculate distance to nearest cell with a value of 2(going around any cell with a value of 1)
dist500m <- gridDistance(bathy2, origin = 2,
                  omit = 1)/1000

# Crop to study area 
dist500m <- dist500m # %>% raster::crop(study) %>% raster::mask(study)

# Save results
# writeRaster(dist500m, "../Data_Processed/Dist500m.tif")


# Plot results
dist500m.df <- as.data.frame(dist500m, xy=TRUE) %>% drop_na()
colnames(dist500m.df) <- c("x","y","dist500")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=dist500m.df, aes(x=x, y=y, fill=dist500), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")
```

## Sea Surface Height

FORMER Source: [GLOBAL OCEAN 1/4Â° PHYSICS ANALYSIS AND FORECAST UPDATED DAILY](https://resources.marine.copernicus.eu/?option=com_csw&view=details&product_id=GLOBAL_ANALYSISFORECAST_PHY_CPL_001_015)

NEW Source: [SEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046](https://resources.marine.copernicus.eu/?option=com_csw&view=details&product_id=SEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046)

```{r sea surface height - reprocessed}

ssh <- nc_open("../Data_Raw/dataset-duacs-rep-global-merged-allsat-phy-l4_20181101-20200531.nc")

{
  sink('../Data_Raw/dataset-duacs-rep-global-merged-allsat-phy-l4_20181101-20200531.txt')
  print(ssh)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(ssh, "longitude")
lat <- ncvar_get(ssh, "latitude", verbose = F)
t <- ncvar_get(ssh, "time")

head(lon)

# Read in data from the ssh variable and verify the dimensions of the array
ssh.array <- ncvar_get(ssh, "adt") # 3dim array
veln.array <- ncvar_get(ssh, "vgos") 
vele.array <- ncvar_get(ssh, "ugos") 
dim(ssh.array)

#### NO FILL VALUE IN THESE DATA? 
# # Identify fill value and replace with NA
# fillvalue <- ncatt_get(ssh, "adt","_FillValue")
# fillvalue
# 
# ssh.array[ssh.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(ssh)

# Convert longitude from 0-360 to -180 to 180
lon <- lon-360

# Isolate and plot a random time step to check
ssh.slice <- ssh.array[,,1]

dim(ssh.slice) #2dim

ssh.r <- raster(t(ssh.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat),ymx=max(lat),
                # Found projection on the website
                crs=4326) %>%
         flip(direction="y")%>%
         raster::projectRaster(crs=prj) %>%
         raster::crop(study)

ssh.df <- as.data.frame(ssh.r, xy=TRUE) %>% drop_na()
colnames(ssh.df) <- c("x","y","ssh")

plot(ssh.r)


# Map of study area with ssh data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=ssh.df, aes(x=x, y=y, fill=ssh), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


test <- aperm(ssh.array, c(2,1,3))
# Make a raster brick of all values 
ssh_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/2016 to yyyy-mm-dd format
# Found this date in metadata text file
t2 <- as.POSIXct("1950-01-01 00:00")+as.difftime(t,units="days")
t2 <- format(t2, "%G-W%V")

class(t2)
# Name raster layers after the date that they portray
names(ssh_brick) <-t2
ssh_brick <- raster::setZ(ssh_brick, t2)

# Save output file
# writeRaster(ssh_brick, "../Data_Processed/ssh.tif")

# Fun animation of the raster brick
# animate(ssh_brick, pause=0.5, n=1)

# Calculate mean monthly ssh rasters 

ssh_week <- zApply(ssh_brick, t2, fun=mean)# Goup by week and calculate mean

# animate(ssh_week, pause=0.5, n=1)

# plot monthly average ssh data for November, 2018
sshweek.df <- as.data.frame(ssh_week[[1]], xy=TRUE)  %>% drop_na()
colnames(sshweek.df) <- c("x","y","ssh")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=sshweek.df, aes(x=x, y=y, fill=ssh), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# animate(ssh_week, pause=0.5, n=1)

writeRaster(ssh_week, "../Data_Processed/ssh_weekly_20181101-20200531.tif", options="INTERLEAVE=BAND")
saveRDS(ssh_week, "../Data_Processed/ssh_weekly_20181101-20200531.rds")

# Save output file
# writeRaster(ssh_week, "../Data_Processed/ssh_weekly_20181101-20200531.nc",
#               overwrite=TRUE, format="CDF",
#               varname="ssh", varunit="m",
#               longname="Sea Surface Height -- raster brick to netCDF",
#               xname="lon",   yname="lat",zname="time",
#               zunit="numeric")


```

## Eddy Kinetic Energy 

Calculated from the same source as SSH. 

```{r EKE calculation and processing - reprocessed}

eke <- nc_open("../Data_Raw/dataset-duacs-rep-global-merged-allsat-phy-l4_20181101-20200531.nc")

{
  sink('../Data_Raw/dataset-duacs-rep-global-merged-allsat-phy-l4_20181101-20200531.txt')
  print(eke)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(eke, "longitude")
lat <- ncvar_get(eke, "latitude", verbose = F)
t <- ncvar_get(eke, "time")

head(lon)

# Read in data from the geostrophic velocity variables and verify the dimensions of the array
veln.array <- ncvar_get(eke, "vgos") 
vele.array <- ncvar_get(eke, "ugos") 

#### NO FILL VALUE IN THESE DATA? 
# # Identify fill value and replace with NA
# fillvalue <- ncatt_get(eke, "adt","_FillValue")
# fillvalue
# 
# eke.array[eke.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(eke)

# vele = surface_geostrophic_eastward_sea_water_velocity
# veln = surface_geostrophic_northward_sea_water_velocity

# Calculation from Wege et al. 2021 
# "eke = 0.5(curru2 + currv2);where curru= horizontal geostrophic velocity; currv = vertical geostrophic velocity" 

eke.array <- 0.5*(vele.array + veln.array)


# Convert longitude from 0-360 to -180 to 180
lon <- lon-360

# Isolate and plot a random time step to check
eke.slice <- eke.array[,,1]

dim(eke.slice) #2dim

eke.r <- raster(t(eke.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat),ymx=max(lat),
                # Found projection on the website
                crs=4326) %>%
         flip(direction="y")%>%
         raster::projectRaster(crs=prj) %>%
         raster::crop(study)

eke.df <- as.data.frame(eke.r, xy=TRUE) %>% drop_na()
colnames(eke.df) <- c("x","y","eke")

plot(eke.r)


# Map of study area with eke data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=eke.df, aes(x=x, y=y, fill=eke), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


test <- aperm(eke.array, c(2,1,3))
# Make a raster brick of all values 
eke_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/2016 to yyyy-mm-dd format
# Found this date in metadata text file
t2 <- as.POSIXct("1950-01-01 00:00")+as.difftime(t,units="days")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(eke_brick) <-t2
eke_brick <- raster::setZ(eke_brick, t2)

# Save output file
# writeRaster(eke_brick, "../Data_Processed/eke.tif")

# Calculate mean weekly  eke rasters 
eke_week <- zApply(eke_brick, t2, fun = mean)

# animate(eke_week, pause=0.5, n=1)

# plot monthly average eke data for November, 2018
ekeweek.df <- as.data.frame(eke_week[[1]], xy=TRUE)  %>% drop_na()
colnames(ekeweek.df) <- c("x","y","eke")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=ekeweek.df, aes(x=x, y=y, fill=eke), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# animate(eke_week, pause=0.5, n=1)

writeRaster(eke_week, "../Data_Processed/eke_weekly_20181101-20200531.tif", options="INTERLEAVE=BAND")
saveRDS(eke_week, "../Data_Processed/eke_weekly_20181101-20200531.rds")

# Save output file
# writeRaster(eke_week, "../Data_Processed/eke_weekly_20181101-20200531.nc",
#               overwrite=TRUE, format="CDF",
#               varname="eke", varunit="m^2/s^2",
#               longname="Eddy Kinetic Energy -- raster brick to netCDF",
#               xname="lon",   yname="lat",zname="time",
#               zunit="numeric")


```


```{r sea surface height - nrt, eval=F}

ssh2 <- nc_open("../Data_Raw/dataset-duacs-nrt-global-merged-allsat-phy-l4_20200601-20200731.nc")

{
  sink('../Data_Raw/dataset-duacs-nrt-global-merged-allsat-phy-l4_20200601-20200731.txt')
  print(ssh2)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(ssh2, "longitude")
lat <- ncvar_get(ssh2, "latitude", verbose = F)
t <- ncvar_get(ssh2, "time")

head(lon)

# Read in data from the ssh2 variable and verify the dimensions of the array
ssh2.array <- ncvar_get(ssh2, "adt") # 3dim array
dim(ssh2.array)

#### NO FILL VALUE IN THESE DATA? 
# # Identify fill value and replace with NA
# fillvalue <- ncatt_get(ssh2, "adt","_FillValue")
# fillvalue
# 
ssh2.array[ssh2.array == NaN] <- NA

# Close netcdf file
nc_close(ssh2)

test <- aperm(ssh2.array, c(2,1,3))
# Make a raster brick of all values 
ssh2_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/2016 to yyyy-mm-dd format
# Found this date in metadata text file
t2 <- as.POSIXct("1950-01-01 00:00")+as.difftime(t,units="days")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(ssh2_brick) <-t2
ssh2_brick <- raster::setZ(ssh2_brick, t2)

# Save output file
# writeRaster(ssh2_brick, "../Data_Processed/ssh2.tif")

# Fun animation of the raster brick
# animate(ssh2_brick, pause=0.5, n=1)

# Calculate mean weekly ssh2 rasters 
ssh2_week <- zApply(ssh2_brick, t2, fun = mean)

# animate(ssh2_week, pause=0.5, n=1)

# plot monthly average ssh data for November, 2018
ssh2week.df <- as.data.frame(ssh2_week[[1]], xy=TRUE)  %>% drop_na()
colnames(ssh2week.df) <- c("x","y","ssh")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=ssh2week.df, aes(x=x, y=y, fill=ssh), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


# temp <- addLayer(ssh_week, ssh2_week)

# animate(ssh2_week, pause=0.5, n=1)

writeRaster(ssh2_week, "../Data_Processed/ssh_weekly_20200601-20200731.tif", options="INTERLEAVE=BAND")
saveRDS(ssh2_week, "../Data_Processed/ssh_weekly_20200601-20200731.rds")

# Save output file
# writeRaster(ssh2_week, "../Data_Processed/ssh_weekly_20200601-20200731.nc",
#               overwrite=TRUE, format="CDF",
#               varname="ssh", varunit="m",
#               longname="Sea Surface Height -- raster brick to netCDF",
#               xname="lon",   yname="lat",zname="time",
#               zunit="numeric")
```

```{r eddy kinetic energy - nrt, eval=F}

eke2 <- nc_open("../Data_Raw/dataset-duacs-nrt-global-merged-allsat-phy-l4_20200601-20200731.nc")

{
  sink('../Data_Raw/dataset-duacs-nrt-global-merged-allsat-phy-l4_20200601-20200731.txt')
  print(eke2)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(eke2, "longitude")
lat <- ncvar_get(eke2, "latitude", verbose = F)
t <- ncvar_get(eke2, "time")

head(lon)

# Read in data from the eke2 variable and verify the dimensions of the array
veln.array <- ncvar_get(eke2, "vgos") 
vele.array <- ncvar_get(eke2, "ugos") 


#### NO FILL VALUE IN THESE DATA? 
# # Identify fill value and replace with NA
# fillvalue <- ncatt_get(eke2, "adt","_FillValue")
# fillvalue
# 
# eke2.array[eke2.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(eke2)

# Calculate EKE based on Bornemann et al. 2021
eke2.array <- 0.5*(vele.array + veln.array)

test <- aperm(eke2.array, c(2,1,3))
# Make a raster brick of all values 
eke2_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/2016 to yyyy-mm-dd format
# Found this date in metadata text file
t2 <- as.POSIXct("1950-01-01 00:00")+as.difftime(t,units="days")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(eke2_brick) <-t2
eke2_brick <- raster::setZ(eke2_brick, t2)


# Calculate mean monthly eke2 rasters 

#get the date from the names of the layers and extract the month
eke2_week <- zApply(eke2_brick, t2, fun = mean)

# animate(eke2_week, pause=0.5, n=1)

# plot monthly average ssh data for November, 2018
eke2week.df <- as.data.frame(eke2_week[[1]], xy=TRUE)  %>% drop_na()
colnames(eke2week.df) <- c("x","y","eke")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=eke2week.df, aes(x=x, y=y, fill=eke), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# animate(eke2_week, pause=0.5, n=1)

writeRaster(eke2_week, "../Data_Processed/eke_weekly_20200601-20200731.tif", options="INTERLEAVE=BAND")
saveRDS(eke2_week, "../Data_Processed/eke_weekly_20200601-20200731.rds")

# Save output file
# writeRaster(eke2_week, "../Data_Processed/eke_weekly_20200601-20200731.nc",
#               overwrite=TRUE, format="CDF",
#               varname="EKE", varunit="m^2/s^2",
#               longname="Eddy Kinetic Energy -- raster brick to netCDF",
#               xname="lon",   yname="lat",zname="time",
#               zunit="numeric")
```


## Wind Speed 

Wind speed data from the Copernicus Marine Service (Met-Op A and B satellites).

Data set name: [GLOBAL OCEAN WIND L4 NEAR REAL TIME 6 HOURLY OBSERVATIONS](https://resources.marine.copernicus.eu/?option=com_csw&view=details&product_id=WIND_GLO_WIND_L4_NRT_OBSERVATIONS_012_004). 

```{r wind speed}

# Open netcdf file 
wind <- nc_open("../Data_Raw/CERSAT-GLO-BLENDED_WIND_L4-V6-OBS_FULL_TIME_SERIE_1626911972037.nc")
# Save metadata to a text file
{
  sink('../Data_Raw/CERSAT-GLO-BLENDED_WIND_L4-V6-OBS_FULL_TIME_SERIE_16269119720374.txt')
  print(wind)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(wind, "lon")
lat <- ncvar_get(wind, "lat", verbose = F)
t <- ncvar_get(wind, "time")

head(lon)

# Read in data from the wind variable and verify the dimensions of the array
wind.array <- ncvar_get(wind, "wind_speed") # 3dim array
dim(wind.array)

# Identify fill value and replace with NA
fillvalue <- ncatt_get(wind, "wind_speed","_FillValue")
fillvalue

wind.array[wind.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(wind)

# Isolate and plot a random time step to check
wind.slice <- wind.array[,,1]

dim(wind.slice) #2dim

wind.r <- raster(t(wind.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat),ymx=max(lat),
                # Found projection on the website
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>%
         flip(direction="y")%>%
         raster::projectRaster(crs=prj)

wind.df <- as.data.frame(wind.r, xy=TRUE) %>% drop_na()
colnames(wind.df) <- c("x","y","windspeed")

plot(wind.r)


# Map of study area with wind data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=wind.df, aes(x=x, y=y, fill=windspeed), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


test <- aperm(wind.array, c(2,1,3))
# Make a raster brick of all values 
wind_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) 

# Convert date from seconds since 01/01/1970 to yyyy-mm-dd format
t2 <- as.POSIXct("1900-01-01 00:00")+as.difftime(t,units="hours")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(wind_brick) <-t2
wind_brick <- raster::setZ(wind_brick, t2)

# Save output file
# writeRaster(wind_brick, "../Data_Processed/wind_AOOS_cropped_4336.tif")

# Fun animation of the raster brick
# animate(wind_brick, pause=0.5, n=1)

# Calculate mean monthly wind rasters 
wind_week <- zApply(wind_brick, t2, fun = mean)

# animate(wind_week, pause=0.5, n=1)

# plot monthly average wind data for November, 2018
windweek.df <- as.data.frame(wind_week[[1]], xy=TRUE)  %>% drop_na()
colnames(windweek.df) <- c("x","y","windspeed")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=windweek.df, aes(x=x, y=y, fill=windspeed), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# animate(wind_week, pause=0.5, n=1)

writeRaster(wind_week, "../Data_Processed/wind_weekly.tif", options="INTERLEAVE=BAND")
saveRDS(wind_week, "../Data_Processed/wind_weekly.rds")


# Save output file
# writeRaster(wind_week, "../Data_Processed/wind_weekly.nc",
              # overwrite=TRUE, format="CDF",
              # varname="wind_speed", varunit="m/s",
              # longname="Wind Speed -- raster brick to netCDF",
              # xname="lon",   yname="lat",zname="time",
              # zunit="numeric")
```

Test to make sure that the netcdf file saved correctly. 

```{r testing netcdf file save, eval=FALSE}

test <-nc_open("../Data_Processed/wind_weekly.nc")

# Save metadata to a text file
{
  sink('../Data_Processed/WIND_Monthly.txt')
  print(test)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(test, "lon")
lat <- ncvar_get(test, "lat", verbose = F)
t <- ncvar_get(test, "time")

head(lon)

# Read in data from the wind variable and verify the dimensions of the array
test.array <- ncvar_get(test, "wind_speed") # 3dim array
dim(test.array)

# Identify fill value and replace with NA
fillvalue <- ncatt_get(test, "wind_speed","_FillValue")
fillvalue

test.array[test.array == fillvalue$value] <- NA

nc_close(test)

test_brick <- brick(test.array, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=prj) 

plot(test_brick[[1]])


test.df <- as.data.frame(test_brick[[1]], xy=TRUE)
colnames(test.df) <- c("x","y","windspeed")

plot(test.r)


# Map of study area with wind data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=test.df, aes(x=x, y=y, fill=windspeed), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


```

## Sea Surface Temperature

[OSTIA: Operational Sea Surface Temperature and Sea Ice Analysis](https://portal.aoos.org/gulf-of-alaska.php#module-metadata/e873784f-7201-416f-bb26-6061c82af388/adc56dd8-e6c6-4d09-abc6-86962fc308eb) from the Alaska Ocean Observing System. 

Citation: 	UK Met Office. 2005. OSTIA L4 SST Analysis. Ver. 1.0. PO.DAAC, CA, USA. Dataset accessed [YYYY-MM-DD] at https://doi.org/10.5067/GHOST-4FK01

Data requested from: https://thredds.axiomdatascience.com/thredds/ncss/AOOS_OSTIA.nc/dataset.html
Variables = analysed_sst, analysis_error, mask, sea_ice_fraction

North = 62
South = 56
West = -155
East = -143
Start = 01 Nov 2018
End = 31 July 2020

NCSS Request URL: https://thredds.axiomdatascience.com/thredds/ncss/AOOS_OSTIA.nc?var=analysed_sst&var=analysis_error&var=mask&var=sea_ice_fraction&north=62&west=-155&east=-143&south=56&disableProjSubset=on&horizStride=1&time_start=2018-11-01T12%3A00%3A00Z&time_end=2020-07-31T12%3A00%3A00Z&timeStride=1&accept=netcdf

```{r sea surface temperature}

# Open netcdf file 
sst <- nc_open("../Data_Raw/AOOS_OSTIA.nc")
# Save metadata to a text file
{
  sink('../Data_Raw/AOOS_OSTIA.txt')
  print(sst)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(sst, "lon")
lat <- ncvar_get(sst, "lat", verbose = F)
t <- ncvar_get(sst, "time")

head(lon)

# Read in data from the SST variable and verify the dimensions of the array
sst.array <- ncvar_get(sst, "analysed_sst") # 3dim array
dim(sst.array)

# Identify fill value and replace with NA
fillvalue <- ncatt_get(sst, "analysed_sst","_FillValue")
fillvalue

sst.array[sst.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(sst)

# Isolate and plot a random time step to check
sst.slice <- sst.array[,,1]

dim(sst.slice) #2dim

sst.r <- raster(t(sst.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat),ymx=max(lat),
                # Found projection on the website
                crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ")) %>%
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>%
         raster::crop(study)

sst.df <- as.data.frame(sst.r, xy=TRUE) %>% drop_na()
colnames(sst.df) <- c("x","y","sst")

plot(sst.r)

# Map of study area with sst data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=sst.df, aes(x=x, y=y, fill=sst), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

test <- aperm(sst.array, c(2,1,3))
# Make a raster brick of all values 
sst_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/1970 to yyyy-mm-dd format
t2 <- as.POSIXct("1900-01-01 00:00")+as.difftime(t,units="secs")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(sst_brick) <- t2
sst_brick <- raster::setZ(sst_brick, t2)


# Calculate the change between any two layers
# tempchange <- sst_brick[[2]]-sst_brick[[1]]
# tempchange

# Calculate mean monthly SST rasters 

#get the date from the names of the layers and extract the month
sst_week <- zApply(sst_brick, by=t2, fun = mean)

# animate(sst_week, pause=0.5, n=1)

writeRaster(sst_week, "../Data_Processed/sst_weekly.tif", options="INTERLEAVE=BAND")
saveRDS(sst_week, "../Data_Processed/sst_weekly.rds")

# writeRaster(sst_week, "../Data_Processed/sst_weekly.nc",
#       overwrite=TRUE, format="CDF",
#       varname="analysed_sst", varunit="m/s",
#       longname="Sea Surface Temperature -- raster brick to netCDF",
#       xname="lon",   yname="lat",zname="time",
#       zunit="numeric")

```

I used this tutorial on indexing [raster time series](https://cyberhelp.sesync.org/raster-time-series-alaska-lesson/index.html#/slides/brick)

For calculating monthly mean values in a [raster brick](https://gis.stackexchange.com/questions/237272/mean-by-month-on-r-stacked-raster). 

```{r merging sea lion locs with SST data, warnings=F, messages=F, eval=F}

# Put seali date into same format as raster brick names
sealis$yearmon <- format(sealis$Date, format="%Y%m")

# Extract monthly average values for SST at seali locs
# Want to look into using an apply function to hopefully make this go faster (it takes ~5 min right now)
for(i in 1:length(sealis$DeployID)){
  if(i %% 100 == 0){
    print(i)
  }
   sealis$SST[i] <- extract(subset(sst_week, 
                                   paste0("index_",sealis$yearmon[i])), sealis[i,])
}

# Looking at the data 
hist(sealis$SST)
length(which(is.na(sealis$SST)))
length(unique(sealis$SST))
length(sealis$SST)
tail(sealis$SST)

hist(as.numeric(sealis$yearmon))
unique(sealis$yearmon)
unique(sealis$DeployID)

# # SST over time at a particular location 
# idx <- match('Aug.13.2019', names(sst_brick))
# plot(sst_brick[[idx]])

```


```{r extra fun stuff, eval=F}
# Correlation between dive temperature and ste
sealitemps <- st_read("../Data_Raw/locs_depths_temps_geodbase_20201130.gdb",
                    layer=seali$name[10]) %>% st_transform(prj)

# Extract monghtly average values for SST at seali locs
# Want to look into using an apply function to hopefullymake this go faster (it takes ~5 min right now)
for(i in 1:length(sealitemps$DeployID)){
  if(i %% 100 == 0){
    print(i)
  }
   sealitemps$SST[i] <- extract(subset(sst_week, 
                                   paste0("index_",sealitemps$yearmon[i])), sealis[i,])
}


```

