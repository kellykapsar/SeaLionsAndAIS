---
title: "Untitled"
author: "Kelly Kapsar"
date: "3/11/2022"
output: html_document
---

```{r}
library(tidyr)
library(dplyr)
library(sf)
library(raster)
library(ggplot2)
library(scales)
library(ggmap)

```


```{r Load in data}
# Load in sea lion data 
# Came from script 2b_DistanceToVessel_HPCC.R
# Comes as one file for each ssl/week combo that must be merged together
# I merged them and saved the output and now I just load the output bc it takes a while to merge

files <- list.files("../Data_Processed/Telemetry/ssl5_season")
alldat <- lapply(files, function(x){readRDS(paste0("../Data_Processed/Telemetry/ssl5_season/", x))})
ssl5 <- data.frame()

for(i in 1:length(alldat)){
  print(i)
  ssl5 <- rbind(ssl5, alldat[[i]])
}
saveRDS(ssl5, "../Data_Processed/Telemetry/ssl5/ssl5_season.rds")

ssl5 <- readRDS("../Data_Processed/Telemetry/ssl5/ssl5_season.rds")


# Projection information for WGS84/UTM Zone 5N (EPSG:32605)
prj <- 32605

```

```{r final cleaning and save}

#################################################
############# CLEAN UP DATA AND SAVE ############ 
#################################################

# Turn used into a factor, log transform skewed vars, and drop geometry
ssl_orig <- ssl5 %>% mutate(used = as.factor(used), 
                           logfish = log(fish+1), 
                           logship = log(ship+1)) %>% 
                    st_drop_geometry()

# Create an individual id
ssl_orig <- ssl_orig %>% group_by(deploy_id) %>% mutate(ind_id = cur_group_id())

# Create a choice_id
ssl <- data.frame()
seasonhr_ids <- unique(ssl_orig$seasonhr_id)
nextid <- 0

for(i in 1:length(unique(ssl_orig$seasonhr_id))){
  print(i)
  used <- ssl_orig %>% filter(seasonhr_id == seasonhr_ids[[i]], used == 1)
  avail <- ssl_orig %>% filter(seasonhr_id == seasonhr_ids[[i]], used == 0)
  
  used$choice_id <- (nextid+1):(length(used$easting)+nextid)
  avail$choice_id <- rep((nextid+1):(length(avail$easting)/5 + nextid), each=5)
  
  temp <- rbind(used, avail)
  ssl <- rbind(ssl, temp)
  
  nextid <- max(ssl$choice_id)
}

# Reorder columns to a more logical order 
covar_names_new <- c("bathymetry", "dist_land", "dist_500m", "slope", "sst", "wind", "logship", "logfish", "prox_fish_km_new", "prox_ship_km_new")

colorder <- c("deploy_id", "ind_id", "seasonhr_id", "year", "choice_id", "used", "northing", "easting", all_of(covar_names_new))

ssl <- ssl[,colorder] %>% as.data.frame()

# Order data appropriately 
ssl <- ssl %>% arrange(seasonhr_id, choice_id, desc(used))


```

```{r save output}


############################################################
############## SAVE OUTPUT WITH ALL VARIABLES ############## 
############################################################

# NOTE: I'M KEEPING INCOMPLETE CASES IN THE DATA SET SINCE IT WON'T BE USED FOR ANALYSIS
# THIS WAY I CAN COMPARE WITH DATA SET BELOW TO SEE HOW MANY OBSERVATIONS WERE REMOVED 

# Save output as non-spatial and without coordinates
saveRDS(ssl, "../Data_Processed/Telemetry/UsedAndAvail_SeasonKDE_20220615.rds")
write.csv(ssl, "../Data_Processed/Telemetry/UsedAndAvail_SeasonKDE_20220615.csv")

# Make it spatial again
ssl_sf <- st_as_sf(ssl, coords = c("easting", "northing"), crs=prj, remove=FALSE)

# Save output as spatial object
st_write(ssl_sf, "../Data_Processed/Telemetry/UsedAndAvail_SeasonKDE_20220615.shp")

# browseURL("https://www.youtube.com/watch?v=K1b8AhIsSYQ")

```