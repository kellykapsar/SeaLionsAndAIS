---
title: "Covariate Data Processing"
author: "Kelly Kapsar"
date: "11/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Import libraries. 
```{r message=FALSE, warning=FALSE}
library(tidyr)
library(dplyr)
library(sf)
library(raster)
library(ggplot2)
library(marmap)
library(ncdf4)
library(anytime)
library(rgdal)
library(scales)

```

Study area boundaries. 

```{r study area warning=FALSE}
# Projection information for WGS84/UTM Zone 5N (EPSG:32605)
prj <- 32605

# Create study area polygon
coords <- data.frame(lat=c(56, 62, 62, 56, 56), lon=c(-155, -155, -143, -143, -155), id="study")
study <- coords %>% 
         st_as_sf(coords = c("lon", "lat"), crs=4326) %>% 
         group_by(id) %>% 
         summarize(geometry = st_combine(geometry)) %>%  
         st_cast("POLYGON") %>% 
         st_transform(prj)
# st_write(study, "../Data_Raw/studyarea.shp")

basemap <- read_sf("../Data_Raw/BBmap.shp") %>% st_transform(prj) %>%  st_buffer(0)

# Crop basemap to buffered extent of study area 
study.buff <- st_buffer(study, 100000) # Buffer study area by 100 km
basemap.crop <- st_crop(basemap, study.buff)

# Map of study area 
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_sf(data=study, fill=NA, color="red")

# Get latlong coordinates for study area for use in downloading other data sets
studylatlon <- study %>% st_transform(4269) %>% st_bbox()
```

## Bathymetry 

Bathymetry data were collected from the [General Bathymetric Chart of the Oceans](gebco.net). You can use the marmap package to load the data and create a "bathy" object type, but I'm not sure exactly how to work with that kind of object, so I just imported the tif data and converted into a raster.    

```{r bathymetry, warning=FALSE}

# bathymarmap <- marmap::getNOAA.bathy(lon1=-155, lon2=-143, lat1=56, lat2=62, resolution=3) 
# # resolution units are in minutes (3 minutes = 0.05 degrees)

# Import raster, reproject to 4336, and crop to study area
bathy <- raster::raster("../Data_Raw/GEBCO_16_Aug_2021/gebco_2021_n64.0_s54.0_w-157.0_e-141.0.tif") %>%
  projectRaster(crs=prj) %>%
  raster::crop(study)

bathyDf <- as.data.frame(bathy, xy=TRUE) %>% drop_na()
colnames(bathyDf) <- c("x","y","depth")

# Save raster object 
# raster::writeRaster(bathy, "../Data_Processed/bathemtry_GEBCO_cropped_4336.tif")

# Map of study area with bathymetric data 
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=bathyDf, aes(x=x, y=y, fill=depth), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# writeRaster(bathy, "../Data_Processed/Bathymetry.tif")

```

## Landmask 

This landmask is at the same scale as the bathymetry data. Note: Zero values were included as land and not water.

```{r GEBCO landmask}
landmask <- bathy
landmask[landmask > 0 | landmask == 0] <- 1
landmask[landmask < 0] <- NA

landmaskDf <- as.data.frame(landmask, xy=TRUE) %>% drop_na()
colnames(landmaskDf) <- c("x","y","land")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_tile(data=landmaskDf, aes(x=x, y=y, fill=land), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# writeRaster(landmask,"../Data_Processed/Landmask_GEBCO.tif", overwrite=TRUE)
```

## Slope

```{r slope}

slope <- terrain(bathy, opt="slope", unit="radians", neighbors=8)


slopeDf <- as.data.frame(slope, xy=TRUE)  %>% drop_na()
colnames(slopeDf) <- c("x","y","slope")

# Map of study area with bathymetric data 
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=slopeDf, aes(x=x, y=y, fill=slope), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

saveRDS(slope, "../Data_Processed/slope.rds")
writeRaster(slope, "../Data_Processed/slope.tif")
```

## Distance to land 

```{r dist2land}
# # Alternate method: Get depth data from NOAA 
# depth <- getNOAA.bathy(lat1=55, lat2=62, lon1=-143, lon2=-156, resolution = 1)
# 
# # Creating color palettes
# blues <- c("lightsteelblue4", "lightsteelblue3",
# "lightsteelblue2", "lightsteelblue1")
# greys <- c(grey(0.6), grey(0.93), grey(0.99))
# 
# # Plot depth data 
# plot(depth, image = TRUE, land = TRUE, lwd = 0.03, 
#      bpal = list(c(0, max(depth), greys),c(min(depth), 0, blues)))
# # Add coastline
# plot(depth, n = 1, lwd = 0.4, add = TRUE)
# 
# # summary(depth)
# 
# # Transect of depth profile at 58N across study area 
# trsect <- get.transect(depth, -155, 58, -148, 58, distance = TRUE)
# plotProfile(trsect)


# Calculate distance to nearest NA cell for all cells in landmask raster 
distland2 <- bathy
values(distland2)[values(distland2) <= 0] = NA

# ID cells on land and water
land <- distland2 > 0
water <- distland2 <= 0

# Land = 1, isobath = 2
distland2[water] <- NA
distland2[land] <- 2

# Calculate distance to land 
distland2 <- gridDistance(distland2, origin = 2)/1000

# Plot results
distland2.df <- as.data.frame(distland2, xy=TRUE) %>% drop_na()
colnames(distland2.df) <- c("x","y","distland")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=distland2.df, aes(x=x, y=y, fill=distland), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# Save output
# writeRaster(distland2, "../Data_Processed/DistLand.tif")
```

## Distance to shelf break

Calculate distance to nearest cell between 400 and 500 m depth. 

```{r 500m shelf break}

# Based on this tutorial: 
# https://www.r-bloggers.com/2020/02/three-ways-to-calculate-distances-in-r/

bathy2 <- bathy

# ID cells on land, shallower than isobath, and deeper than isobath
land <- bathy2 > 0
shallow <- bathy2 > -500
deep <- bathy2 < -510 

# Land = 1, isobath = 2
bathy2[!shallow & !deep] <- 2
bathy2[raster::coordinates(bathy2)[,2] > 6650000] <- 0 # This removes the deeper parts of PWS 
bathy2[land] <- 1

# Calculate distance to nearest cell with a value of 2 (going around any cell with a value of 1)
dist500m <- gridDistance(bathy2, origin = 2,
                  omit = 1)/1000

# Crop to study area 
dist500m <- dist500m # %>% raster::crop(study) %>% raster::mask(study)

# Save results
writeRaster(dist500m, "../Data_Processed/Dist500m.tif")


# Plot results
dist500m.df <- as.data.frame(dist500m, xy=TRUE) %>% drop_na()
colnames(dist500m.df) <- c("x","y","dist500")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=dist500m.df, aes(x=x, y=y, fill=dist500), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")
```

## AIS Data --- Intensity
```{r ais, warning=FALSE}
start <- proc.time()
# Boundary for AIS data acquisition
aisbound_sf <- st_read("../Data_Raw/AIS_Bounds_FromAP/ais_reshape.shp") %>% st_transform(prj) %>% st_crop(study)
aisbound_sp <- aisbound_sf %>% as("Spatial")

# Import raster, reproject to 4336, and crop to study area
fishinglist <- list.files("../Data_Raw/AIS_SSLWeeklySubset/Raster/5000m/", pattern="Fishing")
otherlist <- list.files("../Data_Raw/AIS_SSLWeeklySubset/Raster/5000m/", pattern="Other")
cargolist <- list.files("../Data_Raw/AIS_SSLWeeklySubset/Raster/5000m/", pattern="Cargo")
tankerlist <- list.files("../Data_Raw/AIS_SSLWeeklySubset/Raster/5000m/", pattern="Tanker")

# Create raster bricks for each ship type 
fishingras <- lapply(fishinglist, 
                function(x){projectRaster(raster::raster(paste0("../Data_Raw/AIS_SSLWeeklySubset/Raster/5000m/", x)), crs=prj)})
fishingbrick <- raster::brick(fishingras) %>% raster::mask(aisbound_sp)

otherras <- lapply(otherlist, 
                function(x){projectRaster(raster::raster(paste0("../Data_Raw/AIS_SSLWeeklySubset/Raster/5000m/", x)), crs=prj)})
otherbrick <- raster::brick(otherras) %>% raster::mask(aisbound_sp)

cargoras <- lapply(cargolist, 
                function(x){projectRaster(raster::raster(paste0("../Data_Raw/AIS_SSLWeeklySubset/Raster/5000m/", x)), crs=prj)})
cargobrick <- raster::brick(cargoras) %>% raster::mask(aisbound_sp)

tankerras <- lapply(tankerlist, 
                function(x){projectRaster(raster::raster(paste0("../Data_Raw/AIS_SSLWeeklySubset/Raster/5000m/", x)), crs=prj)})
tankerbrick <- raster::brick(tankerras) %>% raster::mask(aisbound_sp)

shippingbrick <- otherbrick + cargobrick + tankerbrick

# Convert units to km 
shippingbrick <- shippingbrick/1000
fishingbrick <- fishingbrick/1000

# Create list of weeks 
yearmon <- seq(as.Date("2018/11/1"), as.Date("2020/7/31"), "week")
yearmon <- format(yearmon, "%G-W%V")

names(shippingbrick) <- yearmon
names(fishingbrick) <- yearmon

shippingbrick <- raster::setZ(shippingbrick, yearmon)
fishingbrick <- raster::setZ(fishingbrick, yearmon)

# Save raster bricks as netcdf files 
# Save output file
# writeRaster(shippingbrick, "../Data_Processed/AIS_AllOther.nc",
#               overwrite=TRUE, format="CDF",
#               varname="intensity", varunit="km",
#               longname="Shipping intensity (km travelled per cell) -- raster brick to netCDF",
#               xname="lon",   yname="lat",zname="time",
#               zunit="numeric")
# 
# saveRDS(shippingbrick, "../Data_Processed/AIS_AllOther.rds")
# 
# writeRaster(fishingbrick, "../Data_Processed/AIS_Fishing.nc",
#               overwrite=TRUE, format="CDF",
#               varname="intensity", varunit="km",
#               longname="Shipping intensity (km travelled per cell) -- raster brick to netCDF",
#               zname="time", xname="lon",   yname="lat")
# 
# saveRDS(fishingbrick, "../Data_Processed/AIS_Fishing.rds")

# Plot results
# fish.df <- as.data.frame(fishingbrick[[1]], xy=TRUE)  %>% drop_na()
# colnames(fish.df) <- c("x","y","intensity")

# Fun animation of the raster brick
# animate(fishingbrick, pause=0.5, n=1)

# Map of study area with bathymetric data 
# ggplot() +
#   geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
#   geom_raster(data=fish.df, aes(x=x, y=y, fill=intensity), alpha=0.9) +
#   # geom_sf(data=aisbound_sf, fill=NA, color="blue" )+
#   geom_sf(data=study, fill=NA, color="red") +
#   scale_fill_gradient2(trans="log10", low = "black", mid="gray", high="red")

```

## AIS Data -- Proximity 

```{r ais, warning=FALSE}

# Boundary for AIS data acquisition
aisbound_sf <- st_read("../Data_Raw/AIS_Bounds_FromAP/ais_reshape.shp") %>% st_transform(prj) %>% st_crop(study)
aisbound_sp <- aisbound_sf %>% as("Spatial")

# Land mask 
land <- raster("../Data_Processed/Bathymetry.tif")
land[values(land) > 0] <- 1
land[values(land) < 0] <- NA

# # Import ship data, create sf objects, combine into one sf object, and generate year value 
# ships<- list.files("../Data_Raw/AIS_SSLWeeklySubset/Vector", pattern = ".shp") 
# ships <- lapply(ships, function(x){st_read(paste0("../Data_Raw/AIS_SSLWeeklySubset/Vector/", x))}) %>% st_transform(st_crs(ssl4))})
# ships <- do.call(rbind, ships) # Combine all ships into one sf object
# ships <- ships %>% mutate(year = substr(AIS_ID, 11, 14)) # Extract year from AIS_ID

# st_write(ships, "../Data_Raw/AIS_SSLWeeklySubset/Vector/EPSG32605/AllVessels_Reprojected.shp")
# saveRDS(ships, "../Data_Raw/AIS_SSLWeeklySubset/Vector/EPSG32605/AllVessels_Reprojected.rds")

# Then data were sent to AIS_Rasterization_SSLSubset_20210824.R (in Alaska Conservation AIS folder)

# Import raster, reproject to 4336, and crop to study area
fishinglist <- list.files("../Data_Raw/AIS_SSLWeeklySubset/Raster/250m/EPSG32605/", pattern="Fishing")
otherlist <- list.files("../Data_Raw/AIS_SSLWeeklySubset/Raster/250m/EPSG32605/", pattern="Other")
cargolist <- list.files("../Data_Raw/AIS_SSLWeeklySubset/Raster/250m/EPSG32605/", pattern="Cargo")
tankerlist <- list.files("../Data_Raw/AIS_SSLWeeklySubset/Raster/250m/EPSG32605/", pattern="Tanker")

# Create raster bricks for each ship type 
fishingras <- lapply(fishinglist, 
                function(x){raster::raster(paste0("../Data_Raw/AIS_SSLWeeklySubset/Raster/250m/EPSG32605/", x))})

landcrop <- raster::resample(land, fishingras[[1]], method="ngb")

# Set all values > 1 equal to 1
ToOnes <- function(ras){
  values(ras)[values(ras) > 0] <- 1
  return(ras)
}


start <- proc.time()
for(i in 1:92){
  print(i)
  ras <- fishingras[[i]]
  masked <- raster::mask(ras, landcrop, maskvalue = 1)
  maskedbinary <- ToOnes(masked)
  temp <- gridDistance(maskedbinary, origin = 1, omit=NA)/1000
  rasname <- substr(gsub("\\.", "_", names(fishingras[[i]])), 7,30)
  writeRaster(temp, paste0("../Data_Processed/AIS/FishingDistance_", rasname,".tif"))
}
# browseURL("https://www.youtube.com/watch?v=K1b8AhIsSYQ")


otherras <- lapply(otherlist, 
                function(x){raster::raster(paste0("../Data_Raw/AIS_SSLWeeklySubset/Raster/250m/EPSG32605/", x))})

cargoras <- lapply(cargolist, 
                function(x){raster::raster(paste0("../Data_Raw/AIS_SSLWeeklySubset/Raster/250m/EPSG32605/", x))}) 

tankerras <- lapply(tankerlist, 
                function(x){raster::raster(paste0("../Data_Raw/AIS_SSLWeeklySubset/Raster/250m/EPSG32605/", x))})

shippingras <- c()
for(i in 1:92){
  temp <- otherras[[i]] + cargoras[[i]] + tankerras[[i]]
  shippingras <- c(shippingras, temp)
}

for(i in 1:92){
  print(i)
  ras <- shippingras[[i]]
  masked <- raster::mask(ras, landcrop, maskvalue = 1)
  maskedbinary <- ToOnes(masked)
  temp <- gridDistance(maskedbinary, origin = 1, omit=NA)/1000
  rasname <- substr(gsub("\\.", "_", names(fishingras[[i]])), 7,30)
  writeRaster(temp, paste0("../Data_Processed/AIS/ShippingDistance_", rasname,".tif"))
}
(proc.time()-start)/60

```

## Sea Surface Height

FORMER Source: [GLOBAL OCEAN 1/4Â° PHYSICS ANALYSIS AND FORECAST UPDATED DAILY](https://resources.marine.copernicus.eu/?option=com_csw&view=details&product_id=GLOBAL_ANALYSISFORECAST_PHY_CPL_001_015)

NEW Source: [SEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046](https://resources.marine.copernicus.eu/?option=com_csw&view=details&product_id=SEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046)

```{r sea surface height - reprocessed}

ssh <- nc_open("../Data_Raw/dataset-duacs-rep-global-merged-allsat-phy-l4_20181101-20200531.nc")

{
  sink('../Data_Raw/dataset-duacs-rep-global-merged-allsat-phy-l4_20181101-20200531.txt')
  print(ssh)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(ssh, "longitude")
lat <- ncvar_get(ssh, "latitude", verbose = F)
t <- ncvar_get(ssh, "time")

head(lon)

# Read in data from the ssh variable and verify the dimensions of the array
ssh.array <- ncvar_get(ssh, "adt") # 3dim array
veln.array <- ncvar_get(ssh, "vgos") 
vele.array <- ncvar_get(ssh, "ugos") 
dim(ssh.array)

#### NO FILL VALUE IN THESE DATA? 
# # Identify fill value and replace with NA
# fillvalue <- ncatt_get(ssh, "adt","_FillValue")
# fillvalue
# 
# ssh.array[ssh.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(ssh)

# Convert longitude from 0-360 to -180 to 180
lon <- lon-360

# Isolate and plot a random time step to check
ssh.slice <- ssh.array[,,1]

dim(ssh.slice) #2dim

ssh.r <- raster(t(ssh.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat),ymx=max(lat),
                # Found projection on the website
                crs=4326) %>%
         flip(direction="y")%>%
         raster::projectRaster(crs=prj) %>%
         raster::crop(study)

ssh.df <- as.data.frame(ssh.r, xy=TRUE) %>% drop_na()
colnames(ssh.df) <- c("x","y","ssh")

plot(ssh.r)


# Map of study area with ssh data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=ssh.df, aes(x=x, y=y, fill=ssh), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


test <- aperm(ssh.array, c(2,1,3))
# Make a raster brick of all values 
ssh_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/2016 to yyyy-mm-dd format
# Found this date in metadata text file
t2 <- as.POSIXct("1950-01-01 00:00")+as.difftime(t,units="days")
t2 <- format(t2, "%G-W%V")

class(t2)
# Name raster layers after the date that they portray
names(ssh_brick) <-t2
ssh_brick <- raster::setZ(ssh_brick, t2)

# Save output file
# writeRaster(ssh_brick, "../Data_Processed/ssh.tif")

# Fun animation of the raster brick
# animate(ssh_brick, pause=0.5, n=1)

# Calculate mean monthly ssh rasters 

ssh_week <- zApply(ssh_brick, t2, fun=mean)# Goup by week and calculate mean

# animate(ssh_week, pause=0.5, n=1)

# plot monthly average ssh data for November, 2018
sshweek.df <- as.data.frame(ssh_week[[1]], xy=TRUE)  %>% drop_na()
colnames(sshweek.df) <- c("x","y","ssh")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=sshweek.df, aes(x=x, y=y, fill=ssh), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# animate(ssh_week, pause=0.5, n=1)

writeRaster(ssh_week, "../Data_Processed/ssh_weekly_20181101-20200531.tif", options="INTERLEAVE=BAND")
saveRDS(ssh_week, "../Data_Processed/ssh_weekly_20181101-20200531.rds")


# Save output file
# writeRaster(ssh_week, "../Data_Processed/ssh_weekly_20181101-20200531.nc",
#               overwrite=TRUE, format="CDF",
#               varname="ssh", varunit="m",
#               longname="Sea Surface Height -- raster brick to netCDF",
#               xname="lon",   yname="lat",zname="time",
#               zunit="numeric")


```

## Eddy Kinetic Energy 

Calculated from the same source as SSH. 

```{r EKE calculation and processing - reprocessed}

eke <- nc_open("../Data_Raw/dataset-duacs-rep-global-merged-allsat-phy-l4_20181101-20200531.nc")

{
  sink('../Data_Raw/dataset-duacs-rep-global-merged-allsat-phy-l4_20181101-20200531.txt')
  print(eke)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(eke, "longitude")
lat <- ncvar_get(eke, "latitude", verbose = F)
t <- ncvar_get(eke, "time")

head(lon)

# Read in data from the geostrophic velocity variables and verify the dimensions of the array
veln.array <- ncvar_get(eke, "vgos") 
vele.array <- ncvar_get(eke, "ugos") 

#### NO FILL VALUE IN THESE DATA? 
# # Identify fill value and replace with NA
# fillvalue <- ncatt_get(eke, "adt","_FillValue")
# fillvalue
# 
# eke.array[eke.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(eke)

# vele = surface_geostrophic_eastward_sea_water_velocity
# veln = surface_geostrophic_northward_sea_water_velocity

# Calculation from Wege et al. 2021 
# "eke = 0.5(curru2 + currv2);where curru= horizontal geostrophic velocity; currv = vertical geostrophic velocity" 

eke.array <- 0.5*(vele.array + veln.array)


# Convert longitude from 0-360 to -180 to 180
lon <- lon-360

# Isolate and plot a random time step to check
eke.slice <- eke.array[,,1]

dim(eke.slice) #2dim

eke.r <- raster(t(eke.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat),ymx=max(lat),
                # Found projection on the website
                crs=4326) %>%
         flip(direction="y")%>%
         raster::projectRaster(crs=prj) %>%
         raster::crop(study)

eke.df <- as.data.frame(eke.r, xy=TRUE) %>% drop_na()
colnames(eke.df) <- c("x","y","eke")

plot(eke.r)


# Map of study area with eke data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=eke.df, aes(x=x, y=y, fill=eke), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


test <- aperm(eke.array, c(2,1,3))
# Make a raster brick of all values 
eke_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/2016 to yyyy-mm-dd format
# Found this date in metadata text file
t2 <- as.POSIXct("1950-01-01 00:00")+as.difftime(t,units="days")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(eke_brick) <-t2
eke_brick <- raster::setZ(eke_brick, t2)

# Save output file
# writeRaster(eke_brick, "../Data_Processed/eke.tif")

# Calculate mean weekly  eke rasters 
eke_week <- zApply(eke_brick, t2, fun = mean)

# animate(eke_week, pause=0.5, n=1)

# plot monthly average eke data for November, 2018
ekeweek.df <- as.data.frame(eke_week[[1]], xy=TRUE)  %>% drop_na()
colnames(ekeweek.df) <- c("x","y","eke")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=ekeweek.df, aes(x=x, y=y, fill=eke), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# animate(eke_week, pause=0.5, n=1)

writeRaster(eke_week, "../Data_Processed/eke_weekly_20181101-20200531.tif", options="INTERLEAVE=BAND")
saveRDS(eke_week, "../Data_Processed/eke_weekly_20181101-20200531.rds")

# Save output file
# writeRaster(eke_week, "../Data_Processed/eke_weekly_20181101-20200531.nc",
#               overwrite=TRUE, format="CDF",
#               varname="eke", varunit="m^2/s^2",
#               longname="Eddy Kinetic Energy -- raster brick to netCDF",
#               xname="lon",   yname="lat",zname="time",
#               zunit="numeric")


```


```{r sea surface height - nrt, eval=F}

ssh2 <- nc_open("../Data_Raw/dataset-duacs-nrt-global-merged-allsat-phy-l4_20200601-20200731.nc")

{
  sink('../Data_Raw/dataset-duacs-nrt-global-merged-allsat-phy-l4_20200601-20200731.txt')
  print(ssh2)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(ssh2, "longitude")
lat <- ncvar_get(ssh2, "latitude", verbose = F)
t <- ncvar_get(ssh2, "time")

head(lon)

# Read in data from the ssh2 variable and verify the dimensions of the array
ssh2.array <- ncvar_get(ssh2, "adt") # 3dim array
dim(ssh2.array)

#### NO FILL VALUE IN THESE DATA? 
# # Identify fill value and replace with NA
# fillvalue <- ncatt_get(ssh2, "adt","_FillValue")
# fillvalue
# 
ssh2.array[ssh2.array == NaN] <- NA

# Close netcdf file
nc_close(ssh2)

test <- aperm(ssh2.array, c(2,1,3))
# Make a raster brick of all values 
ssh2_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/2016 to yyyy-mm-dd format
# Found this date in metadata text file
t2 <- as.POSIXct("1950-01-01 00:00")+as.difftime(t,units="days")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(ssh2_brick) <-t2
ssh2_brick <- raster::setZ(ssh2_brick, t2)

# Save output file
# writeRaster(ssh2_brick, "../Data_Processed/ssh2.tif")

# Fun animation of the raster brick
# animate(ssh2_brick, pause=0.5, n=1)

# Calculate mean weekly ssh2 rasters 
ssh2_week <- zApply(ssh2_brick, t2, fun = mean)

# animate(ssh2_week, pause=0.5, n=1)

# plot monthly average ssh data for November, 2018
ssh2week.df <- as.data.frame(ssh2_week[[1]], xy=TRUE)  %>% drop_na()
colnames(ssh2week.df) <- c("x","y","ssh")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=ssh2week.df, aes(x=x, y=y, fill=ssh), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


# temp <- addLayer(ssh_week, ssh2_week)

# animate(ssh2_week, pause=0.5, n=1)

writeRaster(ssh2_week, "../Data_Processed/ssh_weekly_20200601-20200731.tif", options="INTERLEAVE=BAND")
saveRDS(ssh2_week, "../Data_Processed/ssh_weekly_20200601-20200731.rds")

# Save output file
# writeRaster(ssh2_week, "../Data_Processed/ssh_weekly_20200601-20200731.nc",
#               overwrite=TRUE, format="CDF",
#               varname="ssh", varunit="m",
#               longname="Sea Surface Height -- raster brick to netCDF",
#               xname="lon",   yname="lat",zname="time",
#               zunit="numeric")
```

```{r eddy kinetic energy - nrt, eval=F}

eke2 <- nc_open("../Data_Raw/dataset-duacs-nrt-global-merged-allsat-phy-l4_20200601-20200731.nc")

{
  sink('../Data_Raw/dataset-duacs-nrt-global-merged-allsat-phy-l4_20200601-20200731.txt')
  print(eke2)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(eke2, "longitude")
lat <- ncvar_get(eke2, "latitude", verbose = F)
t <- ncvar_get(eke2, "time")

head(lon)

# Read in data from the eke2 variable and verify the dimensions of the array
veln.array <- ncvar_get(eke2, "vgos") 
vele.array <- ncvar_get(eke2, "ugos") 


#### NO FILL VALUE IN THESE DATA? 
# # Identify fill value and replace with NA
# fillvalue <- ncatt_get(eke2, "adt","_FillValue")
# fillvalue
# 
# eke2.array[eke2.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(eke2)

# Calculate EKE based on Bornemann et al. 2021
eke2.array <- 0.5*(vele.array + veln.array)

test <- aperm(eke2.array, c(2,1,3))
# Make a raster brick of all values 
eke2_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/2016 to yyyy-mm-dd format
# Found this date in metadata text file
t2 <- as.POSIXct("1950-01-01 00:00")+as.difftime(t,units="days")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(eke2_brick) <-t2
eke2_brick <- raster::setZ(eke2_brick, t2)


# Calculate mean monthly eke2 rasters 

#get the date from the names of the layers and extract the month
eke2_week <- zApply(eke2_brick, t2, fun = mean)

# animate(eke2_week, pause=0.5, n=1)

# plot monthly average ssh data for November, 2018
eke2week.df <- as.data.frame(eke2_week[[1]], xy=TRUE)  %>% drop_na()
colnames(eke2week.df) <- c("x","y","eke")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=eke2week.df, aes(x=x, y=y, fill=eke), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# animate(eke2_week, pause=0.5, n=1)

writeRaster(eke2_week, "../Data_Processed/eke_weekly_20200601-20200731.tif", options="INTERLEAVE=BAND")
saveRDS(eke2_week, "../Data_Processed/eke_weekly_20200601-20200731.rds")

# Save output file
# writeRaster(eke2_week, "../Data_Processed/eke_weekly_20200601-20200731.nc",
#               overwrite=TRUE, format="CDF",
#               varname="EKE", varunit="m^2/s^2",
#               longname="Eddy Kinetic Energy -- raster brick to netCDF",
#               xname="lon",   yname="lat",zname="time",
#               zunit="numeric")
```


## Wind Speed 

Wind speed data from the Copernicus Marine Service (Met-Op A and B satellites).

Data set name: [GLOBAL OCEAN WIND L4 NEAR REAL TIME 6 HOURLY OBSERVATIONS](https://resources.marine.copernicus.eu/?option=com_csw&view=details&product_id=WIND_GLO_WIND_L4_NRT_OBSERVATIONS_012_004). 

```{r wind speed}

# Open netcdf file 
wind <- nc_open("../Data_Raw/CERSAT-GLO-BLENDED_WIND_L4-V6-OBS_FULL_TIME_SERIE_1626911972037.nc")
# Save metadata to a text file
{
  sink('../Data_Raw/CERSAT-GLO-BLENDED_WIND_L4-V6-OBS_FULL_TIME_SERIE_16269119720374.txt')
  print(wind)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(wind, "lon")
lat <- ncvar_get(wind, "lat", verbose = F)
t <- ncvar_get(wind, "time")

head(lon)

# Read in data from the wind variable and verify the dimensions of the array
wind.array <- ncvar_get(wind, "wind_speed") # 3dim array
dim(wind.array)

# Identify fill value and replace with NA
fillvalue <- ncatt_get(wind, "wind_speed","_FillValue")
fillvalue

wind.array[wind.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(wind)

# Isolate and plot a random time step to check
wind.slice <- wind.array[,,1]

dim(wind.slice) #2dim

wind.r <- raster(t(wind.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat),ymx=max(lat),
                # Found projection on the website
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>%
         flip(direction="y")%>%
         raster::projectRaster(crs=prj)

wind.df <- as.data.frame(wind.r, xy=TRUE) %>% drop_na()
colnames(wind.df) <- c("x","y","windspeed")

plot(wind.r)


# Map of study area with wind data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=wind.df, aes(x=x, y=y, fill=windspeed), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


test <- aperm(wind.array, c(2,1,3))
# Make a raster brick of all values 
wind_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) 

# Convert date from seconds since 01/01/1970 to yyyy-mm-dd format
t2 <- as.POSIXct("1900-01-01 00:00")+as.difftime(t,units="hours")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(wind_brick) <-t2
wind_brick <- raster::setZ(wind_brick, t2)

# Save output file
# writeRaster(wind_brick, "../Data_Processed/wind_AOOS_cropped_4336.tif")

# Fun animation of the raster brick
# animate(wind_brick, pause=0.5, n=1)

# Calculate mean monthly wind rasters 
wind_week <- zApply(wind_brick, t2, fun = mean)

# animate(wind_week, pause=0.5, n=1)

# plot monthly average wind data for November, 2018
windweek.df <- as.data.frame(wind_week[[1]], xy=TRUE)  %>% drop_na()
colnames(windweek.df) <- c("x","y","windspeed")

ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=windweek.df, aes(x=x, y=y, fill=windspeed), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

# animate(wind_week, pause=0.5, n=1)

writeRaster(wind_week, "../Data_Processed/wind_weekly.tif", options="INTERLEAVE=BAND", overwrite=T)
saveRDS(wind_week, "../Data_Processed/wind_weekly.rds")
wind <- wind_week
save(wind, file="../Data_Processed/wind_weekly.rda")


# Save output file
# writeRaster(wind_week, "../Data_Processed/wind_weekly.nc",
              # overwrite=TRUE, format="CDF",
              # varname="wind_speed", varunit="m/s",
              # longname="Wind Speed -- raster brick to netCDF",
              # xname="lon",   yname="lat",zname="time",
              # zunit="numeric")
```

Test to make sure that the netcdf file saved correctly. 

```{r testing netcdf file save, eval=FALSE}

test <-nc_open("../Data_Processed/wind_weekly.nc")

# Save metadata to a text file
{
  sink('../Data_Processed/WIND_Monthly.txt')
  print(test)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(test, "lon")
lat <- ncvar_get(test, "lat", verbose = F)
t <- ncvar_get(test, "time")

head(lon)

# Read in data from the wind variable and verify the dimensions of the array
test.array <- ncvar_get(test, "wind_speed") # 3dim array
dim(test.array)

# Identify fill value and replace with NA
fillvalue <- ncatt_get(test, "wind_speed","_FillValue")
fillvalue

test.array[test.array == fillvalue$value] <- NA

nc_close(test)

test_brick <- brick(test.array, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=prj) 

plot(test_brick[[1]])


test.df <- as.data.frame(test_brick[[1]], xy=TRUE)
colnames(test.df) <- c("x","y","windspeed")

plot(test.r)


# Map of study area with wind data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=test.df, aes(x=x, y=y, fill=windspeed), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")


```

## Sea Surface Temperature

[OSTIA: Operational Sea Surface Temperature and Sea Ice Analysis](https://resources.marine.copernicus.eu/?option=com_csw&view=details&product_id=SST_GLO_SST_L4_NRT_OBSERVATIONS_010_001) from the Copernicus Marine Service. 

Variables = analysed_sst, analysis_error, mask, sea_ice_fraction

North = 62
South = 56
West = -155
East = -143
Start = 01 Nov 2018
End = 31 July 2020

```{r sea surface temperature}

# Open netcdf file 
sst <- nc_open("../Data_Raw/METOFFICE-GLO-SST-L4-NRT-OBS-SST-V2_1630513353420.nc")
# Save metadata to a text file
{
  sink('../Data_Raw/METOFFICE-GLO-SST-L4-NRT-OBS-SST-V2_1630513353420.txt')
  print(sst)
  sink()
}

# Read lat lon and time for each observation
lon <- ncvar_get(sst, "lon")
lat <- ncvar_get(sst, "lat", verbose = F)
t <- ncvar_get(sst, "time")

head(lon)

# Read in data from the SST variable and verify the dimensions of the array
sst.array <- ncvar_get(sst, "analysed_sst") # 3dim array
dim(sst.array)

# Identify fill value and replace with NA
fillvalue <- ncatt_get(sst, "analysed_sst","_FillValue")
fillvalue

sst.array[sst.array == fillvalue$value] <- NA

# Close netcdf file
nc_close(sst)

# Conver from kelvin to celcius 
sst.array <- sst.array - 273.15

# Isolate and plot a random time step to check
sst.slice <- sst.array[,,1]

dim(sst.slice) #2dim

sst.r <- raster(t(sst.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat),ymx=max(lat),
                # Found projection on the website
                crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ")) %>%
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>%
         raster::crop(study)

sst.df <- as.data.frame(sst.r, xy=TRUE) %>% drop_na()
colnames(sst.df) <- c("x","y","sst")

plot(sst.r)

# Map of study area with sst data
ggplot() +
  geom_sf(data=basemap.crop, fill="gray", color="black", lwd=0.5) +
  geom_raster(data=sst.df, aes(x=x, y=y, fill=sst), alpha=0.9) +
  scale_fill_gradient2() +
  geom_sf(data=study, fill=NA, color="red")

test <- aperm(sst.array, c(2,1,3))
# Make a raster brick of all values 
sst_brick <- brick(test, xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), 
                crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")) %>% 
         flip(direction="y") %>%
         raster::projectRaster(crs=prj) %>% 
         raster::crop(study)

# Convert date from seconds since 01/01/1970 to yyyy-mm-dd format
t2 <- as.POSIXct("1981-01-01 00:00")+as.difftime(t,units="secs")
t2 <- format(t2, "%G-W%V")

# Name raster layers after the date that they portray
names(sst_brick) <- t2
sst_brick <- raster::setZ(sst_brick, t2)


# Calculate the change between any two layers
# tempchange <- sst_brick[[2]]-sst_brick[[1]]
# tempchange

#get the date from the names of the layers and extract the month
sst_week <- zApply(sst_brick, by=t2, fun = mean)

# animate(sst_week, pause=0.5, n=1)

# writeRaster(sst_week, "../Data_Processed/sst_weekly.tif", options="INTERLEAVE=BAND", overwrite=T)
saveRDS(sst_week, "../Data_Processed/sst_weekly.rds")
sst <- sst_week
save(sst, file= "../Data_Processed/sst_weekly.rda")

# writeRaster(sst_week, "../Data_Processed/sst_weekly.nc",
#       overwrite=TRUE, format="CDF",
#       varname="analysed_sst", varunit="m/s",
#       longname="Sea Surface Temperature -- raster brick to netCDF",
#       xname="lon",   yname="lat",zname="time",
#       zunit="numeric")

```

